{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.data_script import make_BT_design_matrix\n",
    "from package.RankAMIP.logistic import LogisticAMIP\n",
    "from package.RankAMIP.logistic import find_closest_matchups\n",
    "from package.RankAMIP.logistic import isRankingRobust\n",
    "from package.RankAMIP.data_script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is Multi-turn Benchmark Chatbot Arena Data-Dropping Robust?\n",
    "\n",
    "The MT-Bench (Multi-Turn Benchmark) is a curated set of 80 multi-turn dialogue prompts designed to evaluate the conversational and instruction-following capabilities of large language models (LLMs). Each prompt simulates realistic, multi-turn interactions that test a model's ability to maintain context, reason logically, and provide coherent responses across various domains, including general knowledge, reasoning, programming, and open-ended tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8e00e89e7c4d3a9e7f54facdde8985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a148bb0e04c4e079e622e4e0813afdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-c0b431264a82ddc0.parquet:   0%|          | 0.00/650k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f2cee0a1df4be5aca9d8d8d25ac562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-25f4910818759289.parquet:   0%|          | 0.00/739k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b021ac555442958740fff3d93f51ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gpt4_pair split:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ad2d30bf9b4ae5901c4ac4225244b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating human split:   0%|          | 0/3355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import datasets from \n",
    "# https://huggingface.co/datasets/lmsys/mt_bench_human_judgments\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"lmsys/mt_bench_human_judgments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    gpt4_pair: Dataset({\n",
      "        features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn'],\n",
      "        num_rows: 2400\n",
      "    })\n",
      "    human: Dataset({\n",
      "        features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn'],\n",
      "        num_rows: 3355\n",
      "    })\n",
      "})\n",
      "{'question_id': 81, 'model_a': 'alpaca-13b', 'model_b': 'gpt-3.5-turbo', 'winner': 'model_b', 'judge': 'author_2', 'conversation_a': [{'content': 'Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.', 'role': 'user'}, {'content': 'I recently had the pleasure of visiting Hawaii and it quickly became one of my favorite places. From the stunning beaches to the lush mountains, this place has it all. The people are incredibly friendly and the culture is alive and well. One of the highlights of my trip was visiting the Polynesian Cultural Center. Here, I was able to learn about the culture of the native Hawaiian people and try my hand at traditional crafts and activities. I also had a chance to explore some of the natural wonders of the island, including the breathtaking Hanauma Bay and the majestic Waimea Canyon. Whether you’re looking for a relaxing beach vacation or an adventure filled with culture and nature, Hawaii is the perfect destination.', 'role': 'assistant'}, {'content': 'Rewrite your previous response. Start every sentence with the letter A.', 'role': 'user'}, {'content': 'Aloha! I recently had the pleasure of visiting Hawaii and it quickly became one of my favorite places. From the stunning beaches to the lush mountains, this place has it all. The people are incredibly friendly and the culture is alive and well. One of the highlights of my trip was visiting the Polynesian Cultural Center. Here, I was able to learn about the culture of the native Hawaiian people and try my hand at traditional crafts and activities. I also had a chance to explore some of the natural wonders of the island, including the breathtaking Hanauma Bay and the majestic Waimea Canyon. Whether you’re looking for a relaxing beach vacation or an adventure filled with culture and nature, Hawaii is the perfect destination.', 'role': 'assistant'}], 'conversation_b': [{'content': 'Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.', 'role': 'user'}, {'content': \"Aloha! I recently had the pleasure of embarking on a trip to the beautiful island of Hawaii, and let me tell you, the cultural experiences and must-see attractions did not disappoint.\\n\\nFirst on my list was a visit to the Polynesian Cultural Center. This interactive experience immerses you in the cultures of the Pacific Islands, from the intricate dances of the Maori people of New Zealand to the fire knife dancing of Samoa. The center also features a canoe pageant, where different island nations showcase their unique styles of canoeing. It was truly a feast for the senses and a fascinating insight into the diverse cultures of the Pacific.\\n\\nNext up was a trip to the North Shore, which boasts some of the best surf spots in the world. I watched in awe as surfers of all levels tackled the massive waves, and even had the chance to take a lesson myself. It was an exhilarating experience, and I left with a newfound respect for the power of the ocean.\\n\\nOf course, no trip to Hawaii would be complete without a visit to Pearl Harbor. The somber memorial serves as a reminder of the sacrifices made during World War II, and it was a deeply moving experience to pay my respects to the brave men and women who lost their lives on that fateful day.\\n\\nLast but not least, I made sure to indulge in some of the local cuisine. From poke bowls to shave ice, the flavors of Hawaii are truly unique and delicious. A personal favorite was the plate lunch, which typically consists of a protein, rice, and macaroni salad. It may not be the healthiest option, but it sure is tasty!\\n\\nOverall, my trip to Hawaii was an unforgettable experience. The cultural immersion, natural beauty, and delicious food all contributed to an incredible adventure. If you're looking for a destination that has it all, Hawaii should definitely be at the top of your list. Mahalo for reading!\", 'role': 'assistant'}, {'content': 'Rewrite your previous response. Start every sentence with the letter A.', 'role': 'user'}, {'content': \"Absolutely! A recent trip to the beautiful island of Hawaii was an adventure that I will never forget.\\n\\nAs a helpful assistant, I highly recommend a visit to the Polynesian Cultural Center as it immerses you in the cultures of the Pacific Islands.\\n\\nAlso, a trip to the North Shore is a must-see attraction, where you can witness surfers of all levels tackling the massive waves.\\n\\nAdditionally, paying respects to the brave men and women who lost their lives at Pearl Harbor was a deeply moving experience.\\n\\nAnd let's not forget about the delicious local cuisine, from poke bowls to shave ice, the flavors of Hawaii are truly unique and tasty.\\n\\nAll in all, Hawaii has it all - cultural immersion, natural beauty, and delicious food. As an assistant, I encourage you to put Hawaii at the top of your travel list. Aloha!\", 'role': 'assistant'}], 'turn': 1}\n"
     ]
    }
   ],
   "source": [
    "# inspect the available splits\n",
    "print(ds)  \n",
    "# grab the ‘train’ split (or whatever splits ds has)\n",
    "gpt4_pair = ds[\"gpt4_pair\"] \n",
    "human = ds[\"human\"] \n",
    "# look at the first example\n",
    "print(gpt4_pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id     model_a        model_b   winner      judge  \\\n",
       "0           81  alpaca-13b      claude-v1  model_b  gpt4_pair   \n",
       "1           81  alpaca-13b      claude-v1  model_b  gpt4_pair   \n",
       "2           81  alpaca-13b  gpt-3.5-turbo  model_b  gpt4_pair   \n",
       "3           81  alpaca-13b  gpt-3.5-turbo  model_b  gpt4_pair   \n",
       "4           81  alpaca-13b          gpt-4  model_b  gpt4_pair   \n",
       "\n",
       "                                      conversation_a  \\\n",
       "0  [{'content': 'Compose an engaging travel blog ...   \n",
       "1  [{'content': 'Compose an engaging travel blog ...   \n",
       "2  [{'content': 'Compose an engaging travel blog ...   \n",
       "3  [{'content': 'Compose an engaging travel blog ...   \n",
       "4  [{'content': 'Compose an engaging travel blog ...   \n",
       "\n",
       "                                      conversation_b  turn  \n",
       "0  [{'content': 'Compose an engaging travel blog ...     1  \n",
       "1  [{'content': 'Compose an engaging travel blog ...     2  \n",
       "2  [{'content': 'Compose an engaging travel blog ...     1  \n",
       "3  [{'content': 'Compose an engaging travel blog ...     2  \n",
       "4  [{'content': 'Compose an engaging travel blog ...     1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gpt4_pair.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gpt4_pair</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>[{'content': 'Compose an engaging travel blog ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id     model_a        model_b   winner      judge  \\\n",
       "0           81  alpaca-13b      claude-v1  model_b  gpt4_pair   \n",
       "1           81  alpaca-13b      claude-v1  model_b  gpt4_pair   \n",
       "2           81  alpaca-13b  gpt-3.5-turbo  model_b  gpt4_pair   \n",
       "3           81  alpaca-13b  gpt-3.5-turbo  model_b  gpt4_pair   \n",
       "4           81  alpaca-13b          gpt-4  model_b  gpt4_pair   \n",
       "\n",
       "                                      conversation_a  \\\n",
       "0  [{'content': 'Compose an engaging travel blog ...   \n",
       "1  [{'content': 'Compose an engaging travel blog ...   \n",
       "2  [{'content': 'Compose an engaging travel blog ...   \n",
       "3  [{'content': 'Compose an engaging travel blog ...   \n",
       "4  [{'content': 'Compose an engaging travel blog ...   \n",
       "\n",
       "                                      conversation_b  turn  winner_model_a  \\\n",
       "0  [{'content': 'Compose an engaging travel blog ...     1               0   \n",
       "1  [{'content': 'Compose an engaging travel blog ...     2               0   \n",
       "2  [{'content': 'Compose an engaging travel blog ...     1               0   \n",
       "3  [{'content': 'Compose an engaging travel blog ...     2               0   \n",
       "4  [{'content': 'Compose an engaging travel blog ...     1               0   \n",
       "\n",
       "   winner_tie  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column winner_model_a, which is 1 if model_a is preferred, 0 if model_b is preferred\n",
    "df['winner_model_a'] = df['winner'].apply(lambda x: 1 if x == 'model_a' else 0)\n",
    "# create a column called winner_tie that is 1 if the winner is 'tie', else 0\n",
    "df['winner_tie'] = df['winner'].apply(lambda x: 1 if x == 'tie' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ties: 220\n",
      "Proportion of ties: 9.17%\n"
     ]
    }
   ],
   "source": [
    "ties = df[df['winner_tie'] == 1]\n",
    "print(f\"Number of ties: {len(ties)}\")\n",
    "# proportion of ties.\n",
    "print(f\"Proportion of ties: {len(ties) / len(df):.2%}\")\n",
    "# note, the proportion of ties is 9.17% for the LLM-as-judge data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique model names: 6\n"
     ]
    }
   ],
   "source": [
    "# how to get the unique names in both columns\n",
    "model_a_names = df['model_a'].unique()\n",
    "model_b_names = df['model_b'].unique()\n",
    "# combine the two arrays and get the unique names\n",
    "model_names = np.unique(np.concatenate((model_a_names, model_b_names)))\n",
    "# print the number of unique model names\n",
    "print(f\"Number of unique model names: {len(model_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_ties_randomly(df, seed=6):\n",
    "    np.random.seed(seed)\n",
    "    tie_indices = df[df['winner_tie'] == 1].index\n",
    "    # Random choices: 1 means assign to model_a, 0 to model_b\n",
    "    assign_to_a = np.random.choice([0, 1], size=len(tie_indices))\n",
    "    \n",
    "    for idx, assign in zip(tie_indices, assign_to_a):\n",
    "        if assign == 1:\n",
    "            df.at[idx, 'winner_model_a'] = 1\n",
    "            df.at[idx, 'winner_model_b'] = 0\n",
    "        else:\n",
    "            df.at[idx, 'winner_model_a'] = 0\n",
    "            df.at[idx, 'winner_model_b'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 11)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_ties = break_ties_randomly(df,seed=49)\n",
    "# df_no_ties.head(20)\n",
    "df_no_ties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>claude-v1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_a        model_b  winner_model_a\n",
       "0  alpaca-13b      claude-v1               0\n",
       "1  alpaca-13b      claude-v1               0\n",
       "2  alpaca-13b  gpt-3.5-turbo               0\n",
       "3  alpaca-13b  gpt-3.5-turbo               0\n",
       "4  alpaca-13b          gpt-4               0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the model_a, model_b, and winner columns\n",
    "rawBT = df_no_ties[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT.head()\n",
    "# make a design matrix.\n",
    "# X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 5), (2400,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a design matrix.\n",
    "X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robustness results are dependent on how ties are broken \n",
    "changing the random seed changes robustness results.\n",
    "\n",
    "we could think to simply exclude the games that resulted in ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 0\n",
      "testing new matchup:  1 3\n",
      "testing new matchup:  1 None\n",
      "testing new matchup:  1 2\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n",
      "testing new matchup:  1 4\n"
     ]
    }
   ],
   "source": [
    "# checking proportion of random seeds (for tie-breaking) that lead to non-robustness \n",
    "# of dropping 1% of the data.\n",
    "rs_results = []\n",
    "k = 1\n",
    "alphaN = 50 # all models, 1% of the data.\n",
    "for rand_seed in range(200):\n",
    "    df_no_ties = break_ties_randomly(df,seed=rand_seed)\n",
    "\n",
    "    # select the model_a, model_b, and winner columns\n",
    "    rawBT = df_no_ties[['model_a', 'model_b', 'winner_model_a']]\n",
    "    rawBT.head()\n",
    "\n",
    "    # make a design matrix.\n",
    "    X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "    \n",
    "    # run robustness check.\n",
    "    results_curr_seed = isRankingRobust(k, alphaN, X, y)\n",
    "    rs_results.append(results_curr_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_results\n",
    "# find all indices of rs_results that are not (-1, -1, -1, -1, [-1])\n",
    "not_robust_indices = [i for i, result in enumerate(rs_results) if result != (-1, -1, -1, -1, [-1])]\n",
    "# not_robust_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this task arena seems robust to dropping 1% of the data. perhaps it is because the human annotators are 'experts'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new matchup:  1 4\n"
     ]
    }
   ],
   "source": [
    "df_no_ties = break_ties_randomly(df,seed=2)\n",
    "\n",
    "# select the model_a, model_b, and winner columns\n",
    "rawBT = df_no_ties[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT.head()\n",
    "\n",
    "# make a design matrix.\n",
    "X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "\n",
    "# run robustness check.\n",
    "results = {}\n",
    "chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X, y)\n",
    "results[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 50): (1,\n",
       "  4,\n",
       "  0.34440709377443257,\n",
       "  -0.07839674209253555,\n",
       "  array([1306,  617,  587,  646, 1126,  796,  826,  917,  736,  916,  856,\n",
       "         1290,  720,  780,  570,  631,  630,  571, 1741,  853,  553,  192,\n",
       "          193, 2022, 2023,  552, 1363,   72, 1362,  732, 1303, 2052, 2053,\n",
       "         1302, 1752,  733, 1722,  703, 1422, 1423,  613,  103,  102, 1812,\n",
       "         1602, 1872, 1873,  583, 1692,  582]))}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'package.RankAMIP.plot_util' from '/Users/JennyH/Desktop/IsRankingRobust/package/RankAMIP/plot_util.py'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import package.RankAMIP.plot_util\n",
    "from package.RankAMIP.plot_util import *\n",
    "# Make changes to your_local_module.py file (load twice!)\n",
    "# Then reload it\n",
    "importlib.reload(package.RankAMIP.plot_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gpt-4', 2, 4.049409656077162, 4.354695978917397],\n",
       " ['claude-v1', 5, 3.7050025623027296, 4.43309272100994],\n",
       " ['gpt-3.5-turbo', 1, 2.523829859145824, 2.875793406431142],\n",
       " ['vicuna-13b-v1.2', 4, 1.4534455170535812, 1.6929604791958186],\n",
       " ['alpaca-13b', 0, 0.0, 0.0],\n",
       " ['llama-13b', 3, -0.8244371999198913, -0.9316622576088127]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from package.RankAMIP.plot_util import *\n",
    "rankings = return_rankings_list(X, y, results, 1, 50, player_to_id)\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Results.\n",
    "filename_to_save = 'fig/mtbench_llm.png'\n",
    "plot_title = 'Model Rankings on Multi-turn Chatbot Arena (GPT4 Judge)'\n",
    "plot_bt_scores(X, y, rankings, alphaN, 10, plot_title, filename_to_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
