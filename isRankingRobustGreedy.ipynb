{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.logistic import LogisticAMIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Table of Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Step 1: Define teams and latent strengths ---\n",
    "teams = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "team_ids = {name: i for i, name in enumerate(teams)}\n",
    "true_betas = np.array([0.05, 0.04, 0.03, -0.00, -0.01, -0.02])  # (note: we should try out different signal levels later).\n",
    "\n",
    "\n",
    "n_games = 10000\n",
    "matchups = []\n",
    "\n",
    "for _ in range(n_games):\n",
    "    i, j = np.random.choice(6, size=2, replace=False) # randomly choose 2 teams to compete.\n",
    "    beta_diff = true_betas[i] - true_betas[j]\n",
    "    prob_win_i = 1 / (1 + np.exp(-beta_diff))\n",
    "    winner = i if np.random.rand() < prob_win_i else j\n",
    "    matchups.append((i, j, winner))\n",
    "\n",
    "\n",
    "X = np.zeros((n_games, 5))  # We fix beta_0 = 0 and estimate beta_1 and beta_2.\n",
    "y = np.zeros(n_games)\n",
    "\n",
    "for idx, (i, j, winner) in enumerate(matchups):\n",
    "    # Map to reduced index space (beta_0 = 0)\n",
    "    def reduced(k): return k - 1 if k > 0 else None\n",
    "    \n",
    "    if winner == i:\n",
    "        y[idx] = 1\n",
    "        if reduced(i) is not None:\n",
    "            X[idx, reduced(i)] += 1\n",
    "            # print(f\"i, reduced(i): {i, reduced(i)}\")\n",
    "        if reduced(j) is not None:\n",
    "            X[idx, reduced(j)] -= 1\n",
    "    else:\n",
    "        y[idx] = 0\n",
    "        if reduced(j) is not None:\n",
    "            X[idx, reduced(j)] += 1\n",
    "        if reduced(i) is not None:\n",
    "            X[idx, reduced(i)] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 1), (5, 0, 0), (4, 5, 5), (4, 2, 4), (1, 2, 2)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchups[:5] # (i,j,winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = run_logistic_regression(X, y)\n",
    "full_model.coef_[0]\n",
    "pos_p_hats = full_model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04854473, 0.010578  , 0.078925  , 0.01943386, 0.06144881])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_matchups(scores: np.ndarray, K: int) -> 'list[tuple[int,int,float]]':\n",
    "    \"\"\"\n",
    "    For each top-index t in [0..K-1] and each rest-index r in [K..P-1],\n",
    "    compute (t, r, scores[t] - scores[r]) and return as a list.\n",
    "    \"\"\"\n",
    "    P = scores.shape[0]\n",
    "    top  = scores[:K]         # shape (K,)\n",
    "    rest = scores[K:]         # shape (P-K,)\n",
    "\n",
    "    # diffs[t, r-K] = scores[t] - scores[r]\n",
    "    diffs = top[:, None] - rest[None, :]  # shape (K, P-K)\n",
    "\n",
    "    # build flat index arrays of length K*(P-K)\n",
    "    t_idx = np.repeat(np.arange(K), P - K)  # [0,0,…,1,1,…,K-1, …]\n",
    "    r_idx = np.tile(np.arange(K, P), K)  # [K,K+1,…,K,K+1,…, …]\n",
    "\n",
    "    matchups = list(zip(\n",
    "        t_idx.tolist(),\n",
    "        r_idx.tolist(),\n",
    "        diffs.ravel().tolist()\n",
    "    ))\n",
    "    # sort the matchups by the difference.\n",
    "    sorted_matchups = sorted(matchups, key=lambda x: x[2])\n",
    "    \n",
    "    return sorted_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 1.2999999999999998),\n",
       " (0, 2, 2.8),\n",
       " (1, 3, 3.5),\n",
       " (1, 4, 3.7),\n",
       " (0, 3, 5.0),\n",
       " (0, 4, 5.2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array([10.0, 8.5, 7.2, 5.0, 4.8])\n",
    "K = 2\n",
    "matchups = find_closest_matchups(scores, K)\n",
    "matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, 0.0379667285577653, -0.00111148602931576, -0.0018768168345102733, array([4999, 4756, 4770, 4786,  996, 4800, 8523, 8595, 8495, 8471, 8444,\n",
      "       8422, 1074, 1078, 4852, 4829, 8603, 3386, 3390, 8797, 3471, 8783,\n",
      "       3452, 4639, 8700, 4659,  871,  884, 4689, 4706, 8642,  924,  925,\n",
      "       8624, 4853, 8800, 4865, 3313, 1303, 8015]))\n"
     ]
    }
   ],
   "source": [
    "myAMIP = LogisticAMIP(X, y, fit_intercept=False, penalty=None)\n",
    "# inputs: alphaN, player1, player2.\n",
    "# returns: sign_change_amip, sign_change_refit, original_beta_diff, new_beta_diff_amip, new_beta_diff_refit, indices of top alphaN matches.\n",
    "results = myAMIP.AMIP_sign_change(40, 0, 1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRankingRobust(k, alphaN, X, y):\n",
    "    '''\n",
    "    Check if the rank of the top k players/models is robust to data-dropping.\n",
    "    Arg: \n",
    "        k, int, number of top players to consider. \n",
    "        alphaN, int, amount of data willing to drop.\n",
    "        X, np.ndarray, design matrix.\n",
    "        y, np.ndarray, response vector.\n",
    "    Return:\n",
    "        playerA, playerB: int, indices of players/models.\n",
    "        new_beta_diff_refit: float, new beta difference.\n",
    "        indices: list, indices of dropped data.\n",
    "    '''\n",
    "    # run logistic regression on X, y\n",
    "    myAMIP = LogisticAMIP(X, y, fit_intercept=False, penalty=None)\n",
    "    player_scores = myAMIP.model.coef_[0] # (p,)\n",
    "\n",
    "    close_matchups = find_closest_matchups(player_scores, k)\n",
    "    for playerA, playerB, diff in close_matchups: # a list of k(p-k) matchups.\n",
    "        sign_change_amip, sign_change_refit, original_beta_diff,new_beta_diff_amip, new_beta_diff_refit, indices = myAMIP.AMIP_sign_change(alphaN, playerA, playerB)\n",
    "        if sign_change_refit:\n",
    "            return playerA, playerB, original_beta_diff, new_beta_diff_refit, indices\n",
    "    \n",
    "    return -1, -1, -1, -1, -1, [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "alphaN = 15\n",
    "thisPlayerA, thisPlayerB, thisOriginalBetaDiff, thisNewBetaDiff, thisIndices = isRankingRobust(k, alphaN, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 -0.012904076785887723 0.0022168489323046367 [5700 6085 4175 1678 1680 4178 7949  387 6059 9533 4820 3236 3883 9545\n",
      " 1704]\n"
     ]
    }
   ],
   "source": [
    "print(thisPlayerA, thisPlayerB, thisOriginalBetaDiff,thisNewBetaDiff, thisIndices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isRankingRobustLocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
