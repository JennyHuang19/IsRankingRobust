{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.data_script import make_BT_design_matrix\n",
    "from package.RankAMIP.logistic import LogisticAMIP\n",
    "from package.RankAMIP.logistic import find_closest_matchups\n",
    "from package.RankAMIP.logistic import isRankingRobust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is LLM-as-the-Judge Chatbot Arena Data-Dropping Robust?\n",
    "\n",
    "The potsawee/chatbot-arena-llm-judges dataset is a collection of evaluations where large language models (LLMs) act as judges, assessing the quality of responses generated by other LLMs.\n",
    "\n",
    "Studies have shown that strong LLM judges, like GPT-4, can align with human preferences over 80% of the time, suggesting the viability of this approach for large-scale evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# Import datasets from https://huggingface.co/datasets/potsawee/chatbot-arena-llm-judges\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"potsawee/chatbot-arena-llm-judges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'question', 'answer_a', 'answer_b'],\n",
      "        num_rows: 49938\n",
      "    })\n",
      "})\n",
      "{'id': 65089, 'model_a': 'gpt-3.5-turbo-0613', 'model_b': 'mistral-medium', 'winner_model_a': 0, 'winner_model_b': 0, 'winner_tie': 1, 'question': 'explain function calling. how would you call a function?', 'answer_a': 'Function calling is the process of invoking or executing a function in a programming language. To call a function, you need to use the function\\'s name followed by parentheses \"()\". Within the parentheses, you can pass arguments if the function requires any.\\n\\nHere is an example of how to call a function in Python:\\n\\n```python\\n# Define a function\\ndef greet(name):\\n    print(\"Hello, \" + name + \"!\")\\n\\n# Call the function\\ngreet(\"John\")\\n```\\n\\nIn this example, the function \"greet\" is defined with a single parameter \"name\" which is used to print a greeting message. To call the function and pass an argument, we write \"greet(\"John\")\". This will execute the function and print \"Hello, John!\".\\n\\nIt is important to note that the function should be defined before calling it in most programming languages, as the interpreter needs to know about the function\\'s existence before it can be called.', 'answer_b': 'Function calling is the process of invoking a function in a program. A function is a block of code that performs a specific task and can be reused multiple times in a program. Functions help to organize and modularize code, making it more readable and maintainable.\\n\\nTo call a function, you simply write the name of the function followed by parentheses () containing any arguments or parameters that the function requires. Here\\'s an example:\\n```\\nfunction greet(name) {\\n  console.log(\"Hello, \" + name);\\n}\\n\\n// Call the greet function and pass in the argument \"Alice\"\\ngreet(\"Alice\");\\n```\\nIn the example above, the function `greet` takes one parameter, `name`, which is used inside the function to print a greeting message. To call the function, we write the name of the function (`greet`) followed by parentheses containing the argument `\"Alice\"`. When the function is called, the argument `\"Alice\"` is passed to the function, where it is assigned to the `name` parameter. The function then uses the `name` parameter to print the greeting message `\"Hello, Alice\"`.\\n\\nFunctions can also return values, which can be assigned to variables or used in expressions. For example:\\n```\\nfunction addNumbers(a, b) {\\n  return a + b;\\n}\\n\\n// Call the addNumbers function and assign the result to the variable sum\\nvar sum = addNumbers(3, 5);\\nconsole.log(sum); // Output: 8\\n```\\nIn the example above, the function `addNumbers` takes two parameters, `a` and `b`, adds them together, and returns the result. To call the function, we write the name of the function (`addNumbers`) followed by parentheses containing the arguments `3` and `5`. The function calculates the sum of the two arguments (`3 + 5 = 8`) and returns the result (`8`). We then assign the result to the variable `sum` and print it to the console.'}\n"
     ]
    }
   ],
   "source": [
    "# inspect the available splits\n",
    "print(ds)  \n",
    "# grab the ‘train’ split (or whatever splits ds has)\n",
    "train = ds[\"train\"]\n",
    "# look at the first example\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_a</th>\n",
       "      <th>answer_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292873</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Construct a rap battle, in the style of Epic R...</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "      <td>(Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313413</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Why water is not used in bath tub?</td>\n",
       "      <td>Water is actually used in a bath tub. A bath t...</td>\n",
       "      <td>Water is not used in a bath tub because it is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     model_a              model_b  winner_model_a  \\\n",
       "0   65089          gpt-3.5-turbo-0613       mistral-medium               0   \n",
       "1   96401            llama-2-13b-chat  mistral-7b-instruct               1   \n",
       "2  198779                   koala-13b   gpt-3.5-turbo-0314               0   \n",
       "3  292873                  vicuna-13b           gpt-4-0314               0   \n",
       "4  313413  mixtral-8x7b-instruct-v0.1           vicuna-13b               1   \n",
       "\n",
       "   winner_model_b  winner_tie  \\\n",
       "0               0           1   \n",
       "1               0           0   \n",
       "2               1           0   \n",
       "3               1           0   \n",
       "4               0           0   \n",
       "\n",
       "                                            question  \\\n",
       "0  explain function calling. how would you call a...   \n",
       "1  How can I create a test set for a very rare ca...   \n",
       "2  What is the best way to travel from Tel-Aviv t...   \n",
       "3  Construct a rap battle, in the style of Epic R...   \n",
       "4                 Why water is not used in bath tub?   \n",
       "\n",
       "                                            answer_a  \\\n",
       "0  Function calling is the process of invoking or...   \n",
       "1  Creating a test set for a very rare category c...   \n",
       "2  The best way to travel from Tel Aviv to Jerusa...   \n",
       "3  [Zeus]\\nYo, it's the king of the gods on the m...   \n",
       "4  Water is actually used in a bath tub. A bath t...   \n",
       "\n",
       "                                            answer_b  \n",
       "0  Function calling is the process of invoking a ...  \n",
       "1  When building a classifier for a very rare cat...  \n",
       "2  The best way to travel from Tel-Aviv to Jerusa...  \n",
       "3  (Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...  \n",
       "4  Water is not used in a bath tub because it is ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique model names: 64\n"
     ]
    }
   ],
   "source": [
    "# how to get the unique names in both columns\n",
    "model_a_names = df['model_a'].unique()\n",
    "model_b_names = df['model_b'].unique()\n",
    "# combine the two arrays and get the unique names\n",
    "model_names = np.unique(np.concatenate((model_a_names, model_b_names)))\n",
    "# print the number of unique model names\n",
    "print(f\"Number of unique model names: {len(model_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ties: 15641\n",
      "Proportion of ties: 31.32%\n"
     ]
    }
   ],
   "source": [
    "ties = df[df['winner_tie'] == 1]\n",
    "print(f\"Number of ties: {len(ties)}\")\n",
    "# proportion of ties.\n",
    "print(f\"Proportion of ties: {len(ties) / len(df):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15641 ties in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_ties_randomly(df, seed):\n",
    "    np.random.seed(seed)\n",
    "    tie_indices = df[df['winner_tie'] == 1].index\n",
    "    # Random choices: 1 means assign to model_a, 0 to model_b\n",
    "    assign_to_a = np.random.choice([0, 1], size=len(tie_indices))\n",
    "    \n",
    "    for idx, assign in zip(tie_indices, assign_to_a):\n",
    "        if assign == 1:\n",
    "            df.at[idx, 'winner_model_a'] = 1\n",
    "            df.at[idx, 'winner_model_b'] = 0\n",
    "        else:\n",
    "            df.at[idx, 'winner_model_a'] = 0\n",
    "            df.at[idx, 'winner_model_b'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_a              model_b  winner_model_a\n",
       "0          gpt-3.5-turbo-0613       mistral-medium               0\n",
       "1            llama-2-13b-chat  mistral-7b-instruct               1\n",
       "2                   koala-13b   gpt-3.5-turbo-0314               0\n",
       "3                  vicuna-13b           gpt-4-0314               0\n",
       "4  mixtral-8x7b-instruct-v0.1           vicuna-13b               1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_ties = break_ties_randomly(df,seed=0)\n",
    "# df_no_ties.head(20)\n",
    "df_no_ties.shape\n",
    "# select the model_a, model_b, and winner columns\n",
    "rawBT = df_no_ties[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT.head()\n",
    "# make a design matrix.\n",
    "# X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_a             model_b  winner_model_a\n",
       "0     gpt-4-1106-preview        wizardlm-70b               1\n",
       "1               claude-1  gpt-4-1106-preview               1\n",
       "2  deepseek-llm-67b-chat  gpt-4-1106-preview               1\n",
       "3     gpt-4-1106-preview          claude-2.1               1\n",
       "4     gpt-4-1106-preview          gpt-4-0613               0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Move 'gpt-4-1106-preview' to index 0.\n",
    "# Find all rows where gpt-4-1106-preview appears in model_a or model_b\n",
    "mask = (df['model_a'] == 'gpt-4-1106-preview') | (df['model_b'] == 'gpt-4-1106-preview')\n",
    "df = pd.concat([df[mask], df[~mask]]).reset_index(drop=True)\n",
    "new_rawBT = df[['model_a', 'model_b', 'winner_model_a']]\n",
    "new_rawBT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4-1106-preview': 0,\n",
       " 'claude-1': 1,\n",
       " 'deepseek-llm-67b-chat': 2,\n",
       " 'gpt-4-0613': 3,\n",
       " 'gpt-3.5-turbo-0613': 4,\n",
       " 'palm-2': 5,\n",
       " 'gemini-pro': 6,\n",
       " 'claude-instant-1': 7,\n",
       " 'claude-2.1': 8,\n",
       " 'gpt-3.5-turbo-1106': 9,\n",
       " 'mistral-medium': 10,\n",
       " 'mixtral-8x7b-instruct-v0.1': 11,\n",
       " 'llama2-70b-steerlm-chat': 12,\n",
       " 'claude-2.0': 13,\n",
       " 'solar-10.7b-instruct-v1.0': 14,\n",
       " 'llama-2-7b-chat': 15,\n",
       " 'openchat-3.5': 16,\n",
       " 'gemini-pro-dev-api': 17,\n",
       " 'gpt-4-0125-preview': 18,\n",
       " 'stripedhyena-nous-7b': 19,\n",
       " 'mistral-7b-instruct': 20,\n",
       " 'tulu-2-dpo-70b': 21,\n",
       " 'qwen-14b-chat': 22,\n",
       " 'nous-hermes-2-mixtral-8x7b-dpo': 23,\n",
       " 'codellama-34b-instruct': 24,\n",
       " 'chatglm3-6b': 25,\n",
       " 'llama-2-70b-chat': 26,\n",
       " 'gpt-4-0314': 27,\n",
       " 'llama-2-13b-chat': 28,\n",
       " 'wizardlm-70b': 29,\n",
       " 'vicuna-33b': 30,\n",
       " 'pplx-70b-online': 31,\n",
       " 'zephyr-7b-beta': 32,\n",
       " 'openhermes-2.5-mistral-7b': 33,\n",
       " 'pplx-7b-online': 34,\n",
       " 'qwen1.5-4b-chat': 35,\n",
       " 'starling-lm-7b-alpha': 36,\n",
       " 'vicuna-13b': 37,\n",
       " 'dolphin-2.2.1-mistral-7b': 38,\n",
       " 'yi-34b-chat': 39,\n",
       " 'gpt-3.5-turbo-0125': 40,\n",
       " 'qwen1.5-7b-chat': 41,\n",
       " 'wizardlm-13b': 42,\n",
       " 'chatglm2-6b': 43,\n",
       " 'falcon-180b-chat': 44,\n",
       " 'openchat-3.5-0106': 45,\n",
       " 'qwen1.5-72b-chat': 46,\n",
       " 'vicuna-7b': 47,\n",
       " 'koala-13b': 48,\n",
       " 'chatglm-6b': 49,\n",
       " 'dolly-v2-12b': 50,\n",
       " 'stablelm-tuned-alpha-7b': 51,\n",
       " 'llama-13b': 52,\n",
       " 'gpt-3.5-turbo-0314': 53,\n",
       " 'oasst-pythia-12b': 54,\n",
       " 'alpaca-13b': 55,\n",
       " 'fastchat-t5-3b': 56,\n",
       " 'mpt-7b-chat': 57,\n",
       " 'zephyr-7b-alpha': 58,\n",
       " 'RWKV-4-Raven-14B': 59,\n",
       " 'guanaco-33b': 60,\n",
       " 'gpt4all-13b-snoozy': 61,\n",
       " 'mpt-30b-chat': 62,\n",
       " 'mistral-7b-instruct-v0.2': 63}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_players = pd.concat([new_rawBT.iloc[:, 0], new_rawBT.iloc[:, 1]])\n",
    "unique_players = all_players.unique()\n",
    "player_to_id = {player: idx for idx, player in enumerate(unique_players)}\n",
    "player_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49938, 63), (49938,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a design matrix.\n",
    "X, y, player_to_id = make_BT_design_matrix(new_rawBT)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robustness results are dependent on how ties are broken \n",
    "changing the random seed changes robustness results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_results = []\n",
    "for rand_seed in range(10):\n",
    "    df_no_ties = break_ties_randomly(df,seed=rand_seed)\n",
    "    # df_no_ties.head(20)\n",
    "    df_no_ties.shape\n",
    "    # select the model_a, model_b, and winner columns\n",
    "    rawBT = df_no_ties[['model_a', 'model_b', 'winner_model_a']]\n",
    "    rawBT.head()\n",
    "    # make a design matrix.\n",
    "    X, y, player_to_id = make_BT_design_matrix(rawBT)\n",
    "    ###\n",
    "    myAMIP = LogisticAMIP(X, y, fit_intercept=False, penalty=None)\n",
    "    results = myAMIP.AMIP_sign_change(10, 8, 54)\n",
    "    rs_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraction of times the tie-broken arena is non-robust to dropping 10 points\n",
    "sum([rs_results[i][0] for i in range(len(rs_results))]) / len(rs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing new matchup:  17 None\n"
     ]
    }
   ],
   "source": [
    "ks = [1]\n",
    "alphaNs = [10]\n",
    "\n",
    "results = {}\n",
    "for k in ks:\n",
    "    for alphaN in alphaNs:\n",
    "        chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X, y)\n",
    "        results[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 10): (17,\n",
       "  None,\n",
       "  0.0026024924730363454,\n",
       "  -0.02396859349241591,\n",
       "  array([4230, 6362, 1141, 4393,  555, 6400,  583,  599, 4505, 5096]))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'package.RankAMIP.plot_util' from '/Users/JennyH/Desktop/IsRankingRobust/package/RankAMIP/plot_util.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import package.RankAMIP.plot_util\n",
    "from package.RankAMIP.plot_util import *\n",
    "# Make changes to your_local_module.py file\n",
    "# Then reload it\n",
    "importlib.reload(package.RankAMIP.plot_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gpt-4-0125-preview', 18, 0.0026024924730363454, -0.023968593492253342],\n",
       " ['gpt-4-1106-preview', 0, 0.0, 0.0],\n",
       " ['gpt-4-0314', 27, -0.44664797519705846, -0.44973806596932986],\n",
       " ['gpt-4-0613', 3, -0.5161884248635662, -0.5196444422371607],\n",
       " ['qwen1.5-72b-chat', 46, -0.521835041972785, -0.5258672359642106],\n",
       " ['mistral-medium', 10, -0.6171203954360839, -0.6209980561245061],\n",
       " ['claude-1', 1, -0.7077837419976245, -0.710994031968644],\n",
       " ['claude-2.0', 13, -0.7658476724968879, -0.7689856198288763],\n",
       " ['mixtral-8x7b-instruct-v0.1', 11, -0.7732079432536962, -0.7764696103440489],\n",
       " ['pplx-70b-online', 31, -0.8085599127047469, -0.8119145372406565],\n",
       " ['gemini-pro-dev-api', 17, -0.8102657362736976, -0.8135107100566449],\n",
       " ['gemini-pro', 6, -0.810454533058289, -0.813207788956057],\n",
       " ['starling-lm-7b-alpha', 36, -0.8151904718828286, -0.8186996566623835],\n",
       " ['gpt-3.5-turbo-0613', 4, -0.8651733305639048, -0.8686675671610002],\n",
       " ['claude-2.1', 8, -0.8715399571415868, -0.8748098207766041],\n",
       " ['wizardlm-70b', 29, -0.8746890698122955, -0.8781524535002853],\n",
       " ['yi-34b-chat', 39, -0.8865197764957379, -0.889982814787336],\n",
       " ['llama-2-70b-chat', 26, -0.893107254982484, -0.8964702481010655],\n",
       " ['vicuna-33b', 30, -0.8986364361241143, -0.9020755210563708],\n",
       " ['gpt-3.5-turbo-0125', 40, -0.9004231909188163, -0.904514544069716],\n",
       " ['gpt-3.5-turbo-0314', 53, -0.9111209671050183, -0.9145500162568123],\n",
       " ['claude-instant-1', 7, -0.9256839267605403, -0.929052814931357],\n",
       " ['mistral-7b-instruct-v0.2', 63, -0.9296808794857324, -0.9340613997679578],\n",
       " ['nous-hermes-2-mixtral-8x7b-dpo',\n",
       "  23,\n",
       "  -0.9614943418273847,\n",
       "  -0.9659779444226293],\n",
       " ['llama2-70b-steerlm-chat', 12, -0.9987350249645979, -1.0021057895991192],\n",
       " ['solar-10.7b-instruct-v1.0', 14, -1.0186172349576836, -1.0215799548693159],\n",
       " ['deepseek-llm-67b-chat', 2, -1.0370133997578512, -1.0413015362136837],\n",
       " ['tulu-2-dpo-70b', 21, -1.0434278070239822, -1.0467967485927128],\n",
       " ['openchat-3.5', 16, -1.045315672639878, -1.0485607215887884],\n",
       " ['openhermes-2.5-mistral-7b', 33, -1.0527838548458088, -1.05619446907365],\n",
       " ['wizardlm-13b', 42, -1.0755697732074903, -1.078948354356115],\n",
       " ['dolphin-2.2.1-mistral-7b', 38, -1.1042462375116255, -1.1074878579370495],\n",
       " ['llama-2-13b-chat', 28, -1.14745226320153, -1.1508488181957437],\n",
       " ['openchat-3.5-0106', 45, -1.1543363657742618, -1.158564005706377],\n",
       " ['gpt-3.5-turbo-1106', 9, -1.1575811028339924, -1.1606562702831833],\n",
       " ['codellama-34b-instruct', 24, -1.1691589198061747, -1.1725030104383976],\n",
       " ['pplx-7b-online', 34, -1.1705672161382763, -1.17393070649877],\n",
       " ['llama-2-7b-chat', 15, -1.178785848978423, -1.1822577814355477],\n",
       " ['zephyr-7b-beta', 32, -1.183271593496516, -1.1866348640937086],\n",
       " ['guanaco-33b', 60, -1.1898193741848244, -1.1931048039460646],\n",
       " ['qwen1.5-7b-chat', 41, -1.2062151110404544, -1.2098640515171315],\n",
       " ['zephyr-7b-alpha', 58, -1.2663550380775837, -1.2698004900884867],\n",
       " ['mpt-30b-chat', 62, -1.2749329758545354, -1.2784762777383787],\n",
       " ['stripedhyena-nous-7b', 19, -1.2829052251603392, -1.286620170489935],\n",
       " ['vicuna-13b', 37, -1.2947897377458233, -1.2981955462137873],\n",
       " ['falcon-180b-chat', 44, -1.3073126164126416, -1.3108198903841015],\n",
       " ['qwen-14b-chat', 22, -1.3779070397501922, -1.3813745295655804],\n",
       " ['mistral-7b-instruct', 20, -1.4066286057132134, -1.4100466747514835],\n",
       " ['qwen1.5-4b-chat', 35, -1.4188841644137935, -1.4224288090003159],\n",
       " ['palm-2', 5, -1.4340454661971371, -1.4373950804971878],\n",
       " ['vicuna-7b', 47, -1.545628092194591, -1.548964839427901],\n",
       " ['koala-13b', 48, -1.6020796504696908, -1.6054460493930283],\n",
       " ['chatglm3-6b', 25, -1.7551577134565906, -1.7586377871590477],\n",
       " ['gpt4all-13b-snoozy', 61, -1.9682916735624156, -1.971593704427834],\n",
       " ['mpt-7b-chat', 57, -2.0179789787938245, -2.0213098949324317],\n",
       " ['chatglm2-6b', 43, -2.0356327396933023, -2.0389079011892743],\n",
       " ['RWKV-4-Raven-14B', 59, -2.061457954018148, -2.064744352797222],\n",
       " ['alpaca-13b', 55, -2.0771471295608843, -2.080445290882414],\n",
       " ['oasst-pythia-12b', 54, -2.143477453209293, -2.1467583738402576],\n",
       " ['fastchat-t5-3b', 56, -2.222589691549296, -2.2258591003503514],\n",
       " ['chatglm-6b', 49, -2.4065324204356013, -2.409788839282812],\n",
       " ['dolly-v2-12b', 50, -2.4795952700227155, -2.4829491950349345],\n",
       " ['stablelm-tuned-alpha-7b', 51, -2.481501918097789, -2.4848148160214514],\n",
       " ['llama-13b', 52, -2.6225851459504432, -2.6259199409101086]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from package.RankAMIP.plot_util import *\n",
    "rankings = return_rankings_list(X, y, results, 1, 10, player_to_id)\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0026024924730363454, -0.023968593492253342)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the sign of gpt-4-0125-preview flipped.\n",
    "playerA, playerB, orig_out, new_out, indices = results[1, 10]\n",
    "model_full = run_logistic_regression(X, y)\n",
    "Xd = np.delete(X, indices, axis=0)\n",
    "yd = np.delete(y, indices, axis=0)\n",
    "model_d  = run_logistic_regression(Xd, yd)\n",
    "model_full.coef_[0][playerA], model_d.coef_[0][playerA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Results.\n",
    "filename_to_save = 'fig/llm_judge.png'\n",
    "plot_title = 'Model Rankings in LLM Judge Arena'\n",
    "plot_title = 'Model Rankings in LLM Judge Arena'\n",
    "plot_bt_scores(X, y, rankings, alphaN, 10, plot_title, filename_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the score for gpt-4-0125-preview flips with that of gpt-4-1106-preview with only 10 out of 50k matches dropped. These were the original first and second-ranking models, by quite a landslide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dropped human evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_a             model_b  winner_model_a\n",
       "4230  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "6362  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "1141  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "4393  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "555   gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "6400  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "583   gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "599   gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "4505  gpt-4-0125-preview  gpt-4-1106-preview               1\n",
       "5096  gpt-4-0125-preview  gpt-4-1106-preview               1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the human evals that were dropped to change the top model.\n",
    "# dropped comparisons: \n",
    "# get the rows in df that have these indices.\n",
    "mis_df = df.iloc[indices][['model_a', 'model_b', 'winner_model_a']]\n",
    "mis_df\n",
    "# save the df to a csv file.\n",
    "# mistral_df.to_csv('fig/mistral_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of the 10 dropped matches, gpt-4-0125-preview wins against gpt-4-1106-preview. Dropping these 10 matches is enough to demotegpt-4-0125-preview to 2nd place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you were a gamer, what would your gaming PC be? \n",
      " Who is the antagonist of the game Deus Ex?\n",
      "   A: Bowser\n",
      "   B: The Strogg General\n",
      "   C: Anna Navarre\n",
      "   D: None of the above\n",
      "   E: I don't know/there's no such thing.\n",
      "Make a table that compares the pros and cons of the Apple Vision Pro with the Quest 3 and the Quest Pro\n",
      "I have 5 oranges today, I ate 3 oranges last week. How many oranges do I have left?\n",
      "Hi, how are you?\n"
     ]
    }
   ],
   "source": [
    "# MIS: prompts.\n",
    "for prompt in df.iloc[indices[:5]]['question'].tolist():\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I were a gamer, and could choose the specifications for a gaming PC, I would aim for a high-performance setup that balances power, future-proofing, and cost-effectiveness. Here's an ideal configuration based on the latest technology as of early 2023:\n",
      "\n",
      "### Processor (CPU)\n",
      "- **AMD Ryzen 9 7950X** or **Intel Core i9-13900K**\n",
      "  - Both of these CPUs are top-of-the-line for gaming and productivity, offering a high number of cores and threads, excellent single-core performance (important for gaming), and support for the latest technologies.\n",
      "\n",
      "### Graphics Card (GPU)\n",
      "- **NVIDIA GeForce RTX 4080** or **AMD Radeon RX 7900 XT**\n",
      "  - These GPUs are among the best for gaming, offering fantastic performance at 4K resolution, ray tracing capabilities, and support for the latest graphical technologies and APIs.\n",
      "\n",
      "### Memory (RAM)\n",
      "- **32GB DDR5-5600MHz** (or higher)\n",
      "  - 32GB of RAM is more than enough for gaming and ensures smooth performance even in multitasking scenarios or with memory-intensive applications.\n",
      "\n",
      "### Storage\n",
      "- **1TB NVMe PCIe 4.0 SSD** (for the operating system and primary games/applications)\n",
      "  - Fast loading times and quick system responsiveness.\n",
      "- **2TB SATA SSD** (for additional storage of games and media)\n",
      "  - Provides ample space for a large library of games and media content without compromising too much on speed.\n",
      "\n",
      "### Motherboard\n",
      "- Make sure it's compatible with the chosen CPU and supports DDR5 RAM, PCIe 4.0/5.0, and has enough USB ports and expansion slots for future upgrades.\n",
      "\n",
      "### Cooling System\n",
      "- **High-quality AIO (All-In-One) liquid cooler** for the CPU\n",
      "  - Ensures that the CPU operates at optimal temperatures even under heavy loads.\n",
      "- **Good airflow case** with additional case fans\n",
      "  - Maintaining a cool environment for all components is crucial for performance and longevity.\n",
      "\n",
      "### Power Supply (PSU)\n",
      "- **850W 80+ Platinum Certified**\n",
      "  - Provides efficient power delivery and has enough headroom for most upgrades or additional components.\n",
      "\n",
      "### Case\n",
      "- A case that prioritizes airflow, has good cable management options, and supports all the chosen components comfortably.\n",
      "\n",
      "### Peripherals (optional but important for gaming)\n",
      "- **Monitor**: A high refresh rate (144Hz or above), low response time, 1440p or 4K resolution, depending on preference.\n",
      "- **Keyboard and Mouse**: High-quality mechanical keyboard and a mouse with adjustable DPI settings for precision.\n",
      "- **Headset**: With good sound quality and a clear microphone for online gaming.\n",
      "\n",
      "This setup would provide exceptional gaming performance across a wide range of titles, including those with demanding graphics, at high resolutions and frame rates. It also offers a good degree of future-proofing, allowing for new games and software updates to be run comfortably for several years.\n",
      "The correct answer is D: None of the above.\n",
      "\n",
      "The primary antagonist in the original Deus Ex game is Bob Page, a high-ranking member of the secret Majestic 12 organization. None of the provided options directly names the main antagonist of Deus Ex.\n",
      "As of my last update in April 2023, the Apple Vision Pro was officially announced but not yet released, and the details about Quest 3 were speculative based on leaks and rumors. The Quest Pro, however, was available. Please note that some information, especially regarding the Quest 3 and the Apple Vision Pro, might be speculative or based on the information available up to that point. The comparison below is designed to give you a general idea of how these devices might stack up against each other based on available information and the anticipated features of unreleased products. \n",
      "\n",
      "| Feature/Aspect | Apple Vision Pro | Quest 3 | Quest Pro |\n",
      "|----------------|------------------|---------|-----------|\n",
      "| **Display** | High-resolution displays expected, with rumors suggesting advanced micro-OLED technology for crisp and vibrant visuals. | Expected to improve upon the Quest 2's resolution, possibly featuring LCD or OLED technology. | Features mini-LED technology for high-resolution, vibrant visuals with improved clarity and contrast. |\n",
      "| **Tracking** | Anticipated to include advanced spatial and hand tracking capabilities, potentially setting a new standard for VR/AR interaction. | Likely to include improved hand and room-scale tracking over its predecessor, using inside-out tracking technology. | Offers precise hand tracking and room-scale tracking without the need for external sensors, thanks to advanced inside-out tracking technology. |\n",
      "| **Field of View (FoV)** | Expected to offer a wide FoV, enhancing immersion. Specifics were not provided, but Apple aims to improve the immersive experience significantly. | Expected to offer a wider FoV than the Quest 2, though exact specifications are not known. | Provides a relatively wide FoV, enhancing the immersive experience compared to earlier models. |\n",
      "| **Performance** | Anticipated to feature powerful processing capabilities, potentially leveraging Apple's custom silicon to deliver exceptional performance for VR and AR applications. | Expected to be powered by a more advanced processor than the Quest 2, possibly making it suitable for more demanding VR experiences. | Equipped with a powerful Qualcomm Snapdragon XR2 chipset, designed specifically for VR and AR, enabling high-quality experiences. |\n",
      "| **Ecosystem** | Expected to integrate tightly with Apple's ecosystem, offering unique features like seamless integration with other Apple devices and services. | Will benefit from the established Oculus ecosystem, offering a wide range of VR content, including games, educational apps, and more. | Inherits the Quest ecosystem's advantages, with access to a vast library of VR content, and adds exclusive features aimed at professional and business users. |\n",
      "| **Price** | Expected to be premium-priced, reflecting Apple's positioning in the market and the advanced technology used. | Likely to be priced competitively, following Oculus' strategy of making VR more accessible to a broad audience. | Priced at a premium, reflecting its advanced features and positioning as a high-end VR device for professionals and enthusiasts. |\n",
      "| **Pros** | - Advanced AR/VR capabilities expected<br>- High-quality displays<br>- Strong performance<br>- Tight integration with Apple ecosystem | - Improved performance over Quest 2<br>- Competitive pricing expected<br>- Access to the Oculus content library | - High-quality display<br>- Precise tracking capabilities<br>- Professional and business-oriented features<br>- Access to the Oculus content library |\n",
      "| **Cons** | - Likely very expensive<br>- Ecosystem might be more closed, limiting some third-party applications | - Details still speculative<br>- Might not offer as advanced features as premium models | - Expensive compared to consumer-focused models<br>- Might be overkill for casual users |\n",
      "\n",
      "This table provides a broad comparison based on the information available as of April 2023. As the technology landscape is rapidly evolving, I recommend checking the latest reviews and specifications once more concrete information is available, especially for the Apple Vision Pro and the Quest 3, to make the most informed decision.\n",
      "If you have 5 oranges today, and the oranges you ate last week are already accounted for in the past, you currently still have 5 oranges. Eating the 3 oranges last week doesn't affect the number of oranges you have today.\n",
      "I'm just software, so I don't have feelings, but thanks for asking! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# MIS: response A.\n",
    "for responseA in df.iloc[indices[:5]]['answer_a'].tolist():\n",
    "    print(responseA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I were a gamer, my ideal gaming PC would likely focus on high performance to handle the latest games at their best quality settings. Here's a hypothetical build that would make for a powerful gaming system as of my last update in early 2023:\n",
      "\n",
      "**Processor (CPU):** AMD Ryzen 9 5900X or Intel Core i9-12900K – Both of these CPUs are top-of-the-line options for gaming and offer plenty of cores and threads for multitasking and content creation.\n",
      "\n",
      "**Graphics Card (GPU):** NVIDIA GeForce RTX 3080 Ti or AMD Radeon RX 6900 XT – These GPUs are among the best for gaming, offering high frame rates at 4K resolution and support for ray tracing.\n",
      "\n",
      "**Memory (RAM):** 32GB DDR4 3600MHz – This is ample RAM for gaming and will also be beneficial for any streaming or video editing tasks.\n",
      "\n",
      "**Storage:**\n",
      "- Primary SSD: 1TB NVMe PCIe 4.0 SSD for the operating system and frequently played games, which offers fast load times and quick data transfer.\n",
      "- Secondary Storage: 2TB SATA SSD or a larger HDD for additional game storage and other files.\n",
      "\n",
      "**Motherboard:** A high-quality motherboard that matches the chosen CPU socket, with support for PCIe 4.0, multiple M.2 slots for NVMe SSDs, enough USB ports, and possibly built-in Wi-Fi 6 and Bluetooth.\n",
      "\n",
      "**Power Supply Unit (PSU):** At least an 850W 80+ Gold-rated power supply for efficient power delivery and to ensure room for future upgrades.\n",
      "\n",
      "**Cooling System:** A high-quality air cooler or a 240mm (or larger) AIO liquid cooler to keep the CPU temperatures in check during gaming sessions.\n",
      "\n",
      "**Case:** A mid-tower or full-tower case with good airflow, tempered glass side panel to show off the components, and space for cable management to keep things neat.\n",
      "\n",
      "**Operating System:** Windows 11, as it is the latest version and offers the best compatibility with new games and gaming-related features.\n",
      "\n",
      "**Peripherals:**\n",
      "- Monitor: A high-refresh-rate (144Hz or higher) monitor with a 1ms response time, and support for either NVIDIA G-SYNC or AMD FreeSync, depending on the GPU.\n",
      "- Keyboard: A mechanical keyboard with RGB lighting for a tactile and responsive gaming experience.\n",
      "- Mouse: A high-DPI gaming mouse with programmable buttons for better in-game control.\n",
      "- Headset: A comfortable gaming headset with surround sound and a good microphone for clear communication.\n",
      "\n",
      "**Additional Features:**\n",
      "- RGB lighting for aesthetics, if desired.\n",
      "- A high-quality sound card or external DAC for an enhanced audio experience.\n",
      "- UPS (Uninterruptible Power Supply) to protect the system from power surges and outages.\n",
      "\n",
      "This setup would offer a premium gaming experience, capable of running games at high resolutions with the graphics settings maxed out. Of course, the actual components selected can vary based on personal preference, budget, and the availability of parts.\n",
      "D: None of the above\n",
      "\n",
      "In the game Deus Ex, none of the options listed (A: Bowser, B: The Strogg General, C: Anna Navarre) are the main antagonist of the game. Bowser is from the Mario series, and The Strogg General is from the Quake series. While Anna Navarre is a character in Deus Ex, she is not the primary antagonist; she is more of a secondary antagonist or adversary throughout parts of the game. The main antagonistic forces in Deus Ex are the secretive organizations and individuals vying for global control, such as Majestic 12 and its leaders.\n",
      "As of my last update, Apple hasn't released a product named \"Apple Vision Pro,\" and there isn't any official information about such a product. It appears you may be referring to a hypothetical or rumored product. However, for the purpose of this exercise, let's assume \"Apple Vision Pro\" is a virtual reality (VR) or mixed reality (MR) headset, and I will create a comparison table based on typical features users might expect from high-end VR/MR devices.\n",
      "\n",
      "The Oculus Quest 3 is also a speculative product as it hasn't been officially announced or released at the time of the latest knowledge cutoff. We'll assume it's the next iteration of the Oculus Quest line following the Oculus Quest 2.\n",
      "\n",
      "The Quest Pro mentioned might refer to the Oculus Quest Pro, which as of my last update, is not a released product, either. It might be a reference to a higher-end model of the Quest family, so for this comparison, I will use the Oculus Quest 2 as a stand-in for the Quest Pro.\n",
      "\n",
      "Please note that the following table is speculative and based on general expectations for high-end VR/MR headsets:\n",
      "\n",
      "| Feature/Aspect          | Apple Vision Pro (Hypothetical) | Oculus Quest 3 (Hypothetical) | Oculus Quest 2 (Stands in for Quest Pro) |\n",
      "|-------------------------|--------------------------------|-------------------------------|------------------------------------------|\n",
      "| **Display**             | Unknown                        | Unknown                       | Fast-switch LCD; 1832 x 1920 per eye     |\n",
      "| **Field of View**       | Unknown                        | Unknown                       | Approximately 90 degrees                 |\n",
      "| **Tracking**            | Unknown; expected to be inside-out | Unknown; expected to be inside-out | Inside-out tracking with 6DoF          |\n",
      "| **Processor**           | Unknown                        | Unknown                       | Qualcomm Snapdragon XR2                  |\n",
      "| **Weight**              | Unknown                        | Unknown                       | 503 grams                                |\n",
      "| **Battery Life**        | Unknown                        | Unknown                       | 2-3 hours                                |\n",
      "| **Controllers**         | Unknown                        | Unknown                       | Oculus Touch controllers                 |\n",
      "| **Connectivity**        | Unknown                        | Unknown                       | Wi-Fi, USB-C                             |\n",
      "| **Price**               | Unknown                        | Unknown                       | $299 for the 64GB version                |\n",
      "| **Software Ecosystem**  | Unknown; expected to integrate with Apple's ecosystem | Unknown; expected to build on the Oculus ecosystem | Oculus Store    |\n",
      "| **Release Date**        | Unknown                        | Unknown                       | October 13, 2020                         |\n",
      "\n",
      "**Pros (Hypothetical for the Apple Vision Pro and Oculus Quest 3):**\n",
      "- Apple Vision Pro: Expected to have seamless integration with other Apple products and services, potentially offering a polished user experience.\n",
      "- Oculus Quest 3: Likely to build upon the success of the Quest 2 with improved hardware and a large library of VR content.\n",
      "\n",
      "**Cons (Hypothetical for the Apple Vision Pro and Oculus Quest 3):**\n",
      "- Apple Vision Pro: Potentially high price point typical of Apple products.\n",
      "- Oculus Quest 3: As a standalone device, it may still face limitations in processing power compared to PC-tethered headsets.\n",
      "\n",
      "For the actual Oculus Quest 2 (listed here as Quest Pro):\n",
      "**Pros:**\n",
      "- Standalone device with no need for a PC.\n",
      "- Good library of VR content available through the Oculus Store.\n",
      "- Inside-out tracking does not require external sensors.\n",
      "\n",
      "**Cons:**\n",
      "- Limited battery life of 2-3 hours.\n",
      "- Lower processing power compared to PC-tethered headsets.\n",
      "- The field of view and resolution are good but not the highest in the market.\n",
      "\n",
      "Please remember that this comparison is highly speculative and should be taken as a general example of how one might compare such devices, rather than as factual information about existing products.\n",
      "If you have 5 oranges today, the number of oranges you ate last week doesn't affect the current count. Therefore, you still have 5 oranges left today.\n",
      "Hello! I don't have feelings, but I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# MIS: response B.\n",
    "for responseB in df.iloc[indices[:5]]['answer_b'].tolist():\n",
    "    print(responseB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
