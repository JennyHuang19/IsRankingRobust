{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.data_script import make_BT_design_matrix\n",
    "from package.RankAMIP.logistic import LogisticAMIP\n",
    "from package.RankAMIP.logistic import find_closest_matchups\n",
    "from package.RankAMIP.logistic import isRankingRobust\n",
    "from package.RankAMIP.plot_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is ChatBot Arena Data Robust?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets from https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"lmarena-ai/arena-human-preference-55k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
      "        num_rows: 57477\n",
      "    })\n",
      "})\n",
      "{'id': 30192, 'model_a': 'gpt-4-1106-preview', 'model_b': 'gpt-4-0613', 'prompt': '[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"]', 'response_a': '[\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\\\n\\\\nHere are some arguments in favor of and against such policies:\\\\n\\\\n**Arguments in favor:**\\\\n\\\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\\\n\\\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\\\n\\\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\\\n\\\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\\\n\\\\n**Arguments against:**\\\\n\\\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\\\n\\\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\\\n\\\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\\\"tokens,\\\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\\\n\\\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\\\n\\\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one\\'s ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\\\"color-blind\\\\\" or \\\\\"gender-blind\\\\\" approach to hiring and promotions.\\\\n\\\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\\\n\\\\nLet\\'s slice into the debate with a zest of fun:\\\\n\\\\n**Team Pineapple:** \\\\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It\\'s the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\\\"\\\\n\\\\n**Team No-Pineapple:** \\\\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple\\'s sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\\\"\\\\n\\\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it\\'s a match made in heaven, others say it\\'s a culinary crime. But let\\'s face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there\\'s room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\\\u00e9tit, or as they say in pineapple paradise, \\\\\"Aloha-ppetite!\\\\\" \\\\ud83c\\\\udf4d\\\\ud83c\\\\udf55\"]', 'response_b': '[\"As an AI, I don\\'t have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It\\'s a topic with valid arguments on both sides, and it\\'s up to each individual or organization to decide what they believe is right.\",\"As an AI, I don\\'t eat, so I don\\'t have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It\\'s a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]', 'winner_model_a': 1, 'winner_model_b': 0, 'winner_tie': 0}\n"
     ]
    }
   ],
   "source": [
    "# inspect the available splits\n",
    "print(ds)  \n",
    "# grab the ‘train’ split\n",
    "train = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique model names: 64\n"
     ]
    }
   ],
   "source": [
    "# how to get the unique names in both columns\n",
    "model_a_names = df['model_a'].unique()\n",
    "model_b_names = df['model_b'].unique()\n",
    "# combine the two arrays and get the unique names\n",
    "model_names = np.unique(np.concatenate((model_a_names, model_b_names)))\n",
    "# print the number of unique model names\n",
    "print(f\"Number of unique model names: {len(model_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ties: 17761\n",
      "Proportion of ties: 30.90%\n"
     ]
    }
   ],
   "source": [
    "ties = df[df['winner_tie'] == 1]\n",
    "print(f\"Number of ties: {len(ties)}\")\n",
    "# proportion of ties.\n",
    "print(f\"Proportion of ties: {len(ties) / len(df):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the rows that correspond to ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a              model_b  winner_model_a\n",
       "0  gpt-4-1106-preview           gpt-4-0613               1\n",
       "1           koala-13b           gpt-4-0613               0\n",
       "3    llama-2-13b-chat  mistral-7b-instruct               1\n",
       "4           koala-13b   gpt-3.5-turbo-0314               0\n",
       "5          vicuna-13b           gpt-4-0314               0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows in df with df['winner_tie'] == 1\n",
    "df_ties_dropped = df[df['winner_tie'] == 0]\n",
    "df_ties_dropped.shape\n",
    "rawBT_noTies = df_ties_dropped[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT_noTies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV-4-Raven-14B: 799\n",
      "alpaca-13b: 982\n",
      "chatglm-6b: 826\n",
      "chatglm2-6b: 393\n",
      "chatglm3-6b: 695\n",
      "claude-1: 2792\n",
      "claude-2.0: 1741\n",
      "claude-2.1: 3969\n",
      "claude-instant-1: 2922\n",
      "codellama-34b-instruct: 1027\n",
      "deepseek-llm-67b-chat: 519\n",
      "dolly-v2-12b: 556\n",
      "dolphin-2.2.1-mistral-7b: 240\n",
      "falcon-180b-chat: 203\n",
      "fastchat-t5-3b: 702\n",
      "gemini-pro: 1008\n",
      "gemini-pro-dev-api: 1043\n",
      "gpt-3.5-turbo-0125: 576\n",
      "gpt-3.5-turbo-0314: 968\n",
      "gpt-3.5-turbo-0613: 4866\n",
      "gpt-3.5-turbo-1106: 2317\n",
      "gpt-4-0125-preview: 798\n",
      "gpt-4-0314: 2923\n",
      "gpt-4-0613: 4306\n",
      "gpt-4-1106-preview: 5360\n",
      "gpt4all-13b-snoozy: 277\n",
      "guanaco-33b: 457\n",
      "koala-13b: 1102\n",
      "llama-13b: 392\n",
      "llama-2-13b-chat: 1769\n",
      "llama-2-70b-chat: 2315\n",
      "llama-2-7b-chat: 1174\n",
      "llama2-70b-steerlm-chat: 458\n",
      "mistral-7b-instruct: 1098\n",
      "mistral-7b-instruct-v0.2: 72\n",
      "mistral-medium: 2231\n",
      "mixtral-8x7b-instruct-v0.1: 2406\n",
      "mpt-30b-chat: 404\n",
      "mpt-7b-chat: 643\n",
      "nous-hermes-2-mixtral-8x7b-dpo: 235\n",
      "oasst-pythia-12b: 1068\n",
      "openchat-3.5: 1066\n",
      "openchat-3.5-0106: 159\n",
      "openhermes-2.5-mistral-7b: 609\n",
      "palm-2: 1433\n",
      "pplx-70b-online: 1015\n",
      "pplx-7b-online: 897\n",
      "qwen-14b-chat: 709\n",
      "qwen1.5-4b-chat: 124\n",
      "qwen1.5-72b-chat: 370\n",
      "qwen1.5-7b-chat: 140\n",
      "solar-10.7b-instruct-v1.0: 614\n",
      "stablelm-tuned-alpha-7b: 532\n",
      "starling-lm-7b-alpha: 770\n",
      "stripedhyena-nous-7b: 606\n",
      "tulu-2-dpo-70b: 817\n",
      "vicuna-13b: 2371\n",
      "vicuna-33b: 2446\n",
      "vicuna-7b: 1081\n",
      "wizardlm-13b: 1055\n",
      "wizardlm-70b: 1122\n",
      "yi-34b-chat: 973\n",
      "zephyr-7b-alpha: 267\n",
      "zephyr-7b-beta: 1624\n"
     ]
    }
   ],
   "source": [
    "# count number of times each model appears in a match.\n",
    "for model in model_names:\n",
    "    filtered = df_ties_dropped[\n",
    "        (df_ties_dropped['model_a'] == model) | \n",
    "        (df_ties_dropped['model_b'] == model)\n",
    "    ]\n",
    "    print(f\"{model}: {filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39716, 63), (39716,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make design matrix for BT.\n",
    "X, y, player_to_id = make_BT_design_matrix(rawBT_noTies)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Top-k Robustness Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [1, 3, 5, 10, 20]\n",
    "results = {}\n",
    "for k in ks:\n",
    "    alphaN = 1\n",
    "    chatbotA = -1\n",
    "    while chatbotA == -1:\n",
    "        chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X, y)\n",
    "        results[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)\n",
    "        alphaN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = return_rankings_list(X, y, results, 10, 3, player_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top-20 models on full chatbot arena.\n",
    "filename_to_save = 'fig/top20_cba.png'\n",
    "plot_title = 'Model Rankings in Chatbot Arena'\n",
    "plot_bt_scores(X, y, rankings, alphaN, 20, plot_title, filename_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 9): (16,\n",
       "  None,\n",
       "  0.03365783604990017,\n",
       "  -0.0012388871146928558,\n",
       "  array([ 2370,  3227, 38242, 10155, 11353, 17714, 18638, 19742, 32828])),\n",
       " (3, 24): (6,\n",
       "  30,\n",
       "  0.2132132330351283,\n",
       "  -0.007985048942084516,\n",
       "  array([24342, 29361, 38576, 36203, 12188, 15215,  3643, 36863, 27987,\n",
       "          2443, 14012, 12035, 17662,  9137,  4812, 15290, 15514, 27250,\n",
       "         36462,   469, 32825,  7193, 27463, 34265])),\n",
       " (5, 5): (30,\n",
       "  38,\n",
       "  0.03657306106365754,\n",
       "  -0.00615664236957858,\n",
       "  array([ 9754, 19106, 20511,  9565, 26870])),\n",
       " (10, 3): (39,\n",
       "  4,\n",
       "  0.011066418306820314,\n",
       "  -0.0020685804166893362,\n",
       "  array([16514,   601,  7082])),\n",
       " (20, 2): (56,\n",
       "  19,\n",
       "  0.015632264920975247,\n",
       "  -0.01379039709834684,\n",
       "  array([ 2783, 22323]))}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the (k, alpha N) pairs that are top-k non-robust.\n",
    "results_nonrobust = {k: v for k, v in results.items() if v[0] != -1}\n",
    "results_nonrobust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we inspect the ranking flip between the first- and second-place models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in results.\n",
    "import pickle\n",
    "with open(\"results/ChatbotArenaNonrobust.pkl\", \"rb\") as f:\n",
    "    chatBotArenaDataDropped = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292873</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
       "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
       "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "3  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "4  292873          vicuna-13b           gpt-4-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"How can I create a test set for a very rare ...   \n",
       "3  [\"What is the best way to travel from Tel-Aviv...   \n",
       "4  [\"Construct a rap battle, in the style of Epic...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Creating a test set for a very rare category...   \n",
       "3  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "4  [\"[Zeus]\\nYo, it's the king of the gods on the...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"When building a classifier for a very rare c...               1   \n",
       "3  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "4  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           0  \n",
       "3               1           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArena_noTies = pd.read_csv(\"data/chatBotArena_noTies.csv\")\n",
    "chatBotArena_noTies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 evals were dropped to flip model i.d. 16 and i.d. None (the reference model).\n",
    "\n",
    "The name of these models are: \n",
    "('gpt-4-0125-preview', 0: 'gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games between GPT-4-1106 and GPT-4-0125:  67\n"
     ]
    }
   ],
   "source": [
    "## Count number of games between the two models that changed ranks.\n",
    "is_gpt41106_gpt40125 = (\n",
    "    (chatBotArena_noTies['model_a'].str.contains('gpt-4-0125-preview') & chatBotArena_noTies['model_b'].str.contains('gpt-4-1106-preview')) |\n",
    "    (chatBotArena_noTies['model_a'].str.contains('gpt-4-1106-preview') & chatBotArena_noTies['model_b'].str.contains('gpt-4-0125-preview'))\n",
    ")\n",
    "\n",
    "num_gpt41106_gpt40125 = chatBotArena_noTies[is_gpt41106_gpt40125].shape[0]\n",
    "print(\"Number of games between GPT-4-1106 and GPT-4-0125: \", num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                (gpt-4-0613, gpt-4-1106-preview)\n",
       "1                         (gpt-4-0613, koala-13b)\n",
       "2         (llama-2-13b-chat, mistral-7b-instruct)\n",
       "3                 (gpt-3.5-turbo-0314, koala-13b)\n",
       "4                        (gpt-4-0314, vicuna-13b)\n",
       "                           ...                   \n",
       "39711                      (claude-1, gpt-4-0613)\n",
       "39712              (claude-2.0, llama-2-13b-chat)\n",
       "39713                      (alpaca-13b, claude-1)\n",
       "39714                    (palm-2, tulu-2-dpo-70b)\n",
       "39715    (gemini-pro-dev-api, gpt-4-1106-preview)\n",
       "Name: model_pair, Length: 39716, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model pairs (sorted to group symmetric pairs)\n",
    "chatBotArena_noTies['model_pair'] = chatBotArena_noTies.apply(lambda row: tuple(sorted([row['model_a'], row['model_b']])), axis=1)\n",
    "chatBotArena_noTies['model_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of games per model pair: 31.900401606425703\n"
     ]
    }
   ],
   "source": [
    "# Count number of games per model pair\n",
    "pair_counts = chatBotArena_noTies['model_pair'].value_counts()\n",
    "\n",
    "# Compute average\n",
    "average_games_per_pair = pair_counts.mean()\n",
    "print(\"Average number of games per model pair:\", average_games_per_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of games that GPT-4-0125 won:  0.5373134328358209\n"
     ]
    }
   ],
   "source": [
    "# Find the win margin between 'gpt-4-0125-preview' and 'gpt-4-1106-preview'\n",
    "# that is, find all games that are between the two models.\n",
    "dfFlippedRanking = chatBotArena_noTies[is_gpt41106_gpt40125]\n",
    "## Count number of games between that 'gpt-4-0125-preview' won.\n",
    "gpt40125_wins = (\n",
    "    (dfFlippedRanking['model_a'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_a'] == 1) |\n",
    "    (dfFlippedRanking['model_b'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_b'] == 1)\n",
    ")\n",
    "num_gpt40125_wins = dfFlippedRanking[gpt40125_wins].shape[0]\n",
    "print(\"Proportion of games that GPT-4-0125 won: \", num_gpt40125_wins / num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player involvement in dropped matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 9): (16,\n",
       "  None,\n",
       "  0.03365783604990017,\n",
       "  -0.0012388871146928558,\n",
       "  array([ 2370,  3227, 38242, 10155, 11353, 17714, 18638, 19742, 32828])),\n",
       " (3, 24): (6,\n",
       "  30,\n",
       "  0.2132132330351283,\n",
       "  -0.007985048942084516,\n",
       "  array([24342, 29361, 38576, 36203, 12188, 15215,  3643, 36863, 27987,\n",
       "          2443, 14012, 12035, 17662,  9137,  4812, 15290, 15514, 27250,\n",
       "         36462,   469, 32825,  7193, 27463, 34265])),\n",
       " (5, 5): (30,\n",
       "  38,\n",
       "  0.03657306106365754,\n",
       "  -0.00615664236957858,\n",
       "  array([ 9754, 19106, 20511,  9565, 26870])),\n",
       " (10, 3): (39,\n",
       "  4,\n",
       "  0.011066418306820314,\n",
       "  -0.0020685804166893362,\n",
       "  array([16514,   601,  7082])),\n",
       " (20, 2): (56,\n",
       "  19,\n",
       "  0.015632264920975247,\n",
       "  -0.01379039709834684,\n",
       "  array([ 2783, 22323]))}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArenaDataDropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tuple = chatBotArenaDataDropped[(1, 9)] # = 0 # change none to -1 (gpt-4-1106-preview).\n",
    "new_tuple = tuple(-1 if i == 1 and val is None else val for i, val in enumerate(old_tuple))\n",
    "results_nonrobust[(1, 9)] = new_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-aN</th>\n",
       "      <th>playerA</th>\n",
       "      <th>playerB</th>\n",
       "      <th>original_beta_diff</th>\n",
       "      <th>new_beta_diff_refit</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 9)</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>[2370, 3227, 38242, 10155, 11353, 17714, 18638...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 24)</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0.213213</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>[24342, 29361, 38576, 36203, 12188, 15215, 364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>[9754, 19106, 20511, 9565, 26870]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 3)</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>[16514, 601, 7082]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 2)</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>-0.013790</td>\n",
       "      <td>[2783, 22323]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k-aN  playerA  playerB  original_beta_diff  new_beta_diff_refit  \\\n",
       "0   (1, 9)       17        0            0.033658            -0.001239   \n",
       "1  (3, 24)        7       31            0.213213            -0.007985   \n",
       "2   (5, 5)       31       39            0.036573            -0.006157   \n",
       "3  (10, 3)       40        5            0.011066            -0.002069   \n",
       "4  (20, 2)       57       20            0.015632            -0.013790   \n",
       "\n",
       "                                             indices  \n",
       "0  [2370, 3227, 38242, 10155, 11353, 17714, 18638...  \n",
       "1  [24342, 29361, 38576, 36203, 12188, 15215, 364...  \n",
       "2                  [9754, 19106, 20511, 9565, 26870]  \n",
       "3                                 [16514, 601, 7082]  \n",
       "4                                      [2783, 22323]  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for (k, aN), (playerA, playerB, original_beta_diff, new_beta_diff_refit, indices) in results_nonrobust.items():\n",
    "    rows.append({\n",
    "        \"k-aN\": (k, aN),\n",
    "        \"playerA\": playerA + 1, # to account for the reference index.\n",
    "        \"playerB\": playerB + 1,\n",
    "        \"original_beta_diff\": original_beta_diff,\n",
    "        \"new_beta_diff_refit\": new_beta_diff_refit,\n",
    "        \"indices\": indices\n",
    "    })\n",
    "cba_results = pd.DataFrame(rows)\n",
    "cba_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the mapping.\n",
    "id_to_player = {v: k for k, v in player_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the results.\n",
    "cba_results.head()\n",
    "cba_results['playerA_Name'] = cba_results['playerA'].map(id_to_player)\n",
    "cba_results['playerB_Name'] = cba_results['playerB'].map(id_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>301329900</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>nous-hermes-2-mixtral-8x7b-dpo</td>\n",
       "      <td>[\"Your task is to perform relation and entity ...</td>\n",
       "      <td>[\"GutMicrobiota(x) \\u2227 GoodHealth(y) \\u2192...</td>\n",
       "      <td>[\"Extraction 1:\\n\\nGutMicrobiota(x) \\u2227 Goo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22323</th>\n",
       "      <td>2387156917</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>nous-hermes-2-mixtral-8x7b-dpo</td>\n",
       "      <td>[\"In a context of plant encyclopedia where we ...</td>\n",
       "      <td>[\"1. **Unusual Foliage Coloration**: The White...</td>\n",
       "      <td>[\"1. White Firs (Abies concolor) are native to...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a                         model_b  \\\n",
       "2783    301329900  gpt-4-1106-preview  nous-hermes-2-mixtral-8x7b-dpo   \n",
       "22323  2387156917  gpt-4-1106-preview  nous-hermes-2-mixtral-8x7b-dpo   \n",
       "\n",
       "                                                  prompt  \\\n",
       "2783   [\"Your task is to perform relation and entity ...   \n",
       "22323  [\"In a context of plant encyclopedia where we ...   \n",
       "\n",
       "                                              response_a  \\\n",
       "2783   [\"GutMicrobiota(x) \\u2227 GoodHealth(y) \\u2192...   \n",
       "22323  [\"1. **Unusual Foliage Coloration**: The White...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "2783   [\"Extraction 1:\\n\\nGutMicrobiota(x) \\u2227 Goo...               0   \n",
       "22323  [\"1. White Firs (Abies concolor) are native to...               0   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "2783                1           0  \n",
       "22323               1           0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each index, find the corresponding row in the original dataframe.\n",
    "indices = [2783, 22323] # [149, 4412] \n",
    "chatBotArena_noTies.iloc[indices]\n",
    "# find the proportion of games where neither "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dropped human evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-aN</th>\n",
       "      <th>playerA</th>\n",
       "      <th>playerB</th>\n",
       "      <th>original_beta_diff</th>\n",
       "      <th>new_beta_diff_refit</th>\n",
       "      <th>indices</th>\n",
       "      <th>playerA_Name</th>\n",
       "      <th>playerB_Name</th>\n",
       "      <th>prop_both</th>\n",
       "      <th>prop_one</th>\n",
       "      <th>prop_neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 9)</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>[2370, 3227, 38242, 10155, 11353, 17714, 18638...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 24)</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0.213213</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>[24342, 29361, 38576, 36203, 12188, 15215, 364...</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>[9754, 19106, 20511, 9565, 26870]</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 3)</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>[16514, 601, 7082]</td>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 2)</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>-0.013790</td>\n",
       "      <td>[2783, 22323]</td>\n",
       "      <td>nous-hermes-2-mixtral-8x7b-dpo</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k-aN  playerA  playerB  original_beta_diff  new_beta_diff_refit  \\\n",
       "0   (1, 9)       17        0            0.033658            -0.001239   \n",
       "1  (3, 24)        7       31            0.213213            -0.007985   \n",
       "2   (5, 5)       31       39            0.036573            -0.006157   \n",
       "3  (10, 3)       40        5            0.011066            -0.002069   \n",
       "4  (20, 2)       57       20            0.015632            -0.013790   \n",
       "\n",
       "                                             indices  \\\n",
       "0  [2370, 3227, 38242, 10155, 11353, 17714, 18638...   \n",
       "1  [24342, 29361, 38576, 36203, 12188, 15215, 364...   \n",
       "2                  [9754, 19106, 20511, 9565, 26870]   \n",
       "3                                 [16514, 601, 7082]   \n",
       "4                                      [2783, 22323]   \n",
       "\n",
       "                     playerA_Name        playerB_Name  prop_both  prop_one  \\\n",
       "0              gpt-4-0125-preview  gpt-4-1106-preview        1.0       0.0   \n",
       "1                      gpt-4-0314    qwen1.5-72b-chat        0.0       1.0   \n",
       "2                qwen1.5-72b-chat      mistral-medium        0.0       1.0   \n",
       "3                     yi-34b-chat          gemini-pro        1.0       0.0   \n",
       "4  nous-hermes-2-mixtral-8x7b-dpo          vicuna-33b        0.0       1.0   \n",
       "\n",
       "   prop_neither  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_arena_results_with_props = add_match_proportions(cba_results, chatBotArena_noTies)\n",
    "chatbot_arena_results_with_props.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rank-flipping between mistral and qwen, a total of 5 evaluations where qwen played and won against gpt-4-1106-preview was enough to move its ranking to above that of mistral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>1051544564</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"\\nread this content. Do not change the conte...</td>\n",
       "      <td>[\"6. Use AI Writing Tools\\n\\nIncorporating AI ...</td>\n",
       "      <td>[\"6. Use AI to Your Advantage\\n\\nIn this age o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19106</th>\n",
       "      <td>2049273519</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>[\"Which is the newest model that also contain ...</td>\n",
       "      <td>[\"I'm sorry, but your question isn't clear. Wh...</td>\n",
       "      <td>[\"As an AI, I don't have real-time access to u...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>2199125192</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"Please answer this questions in 8 sentences ...</td>\n",
       "      <td>[\"1. When a legal description appears clear in...</td>\n",
       "      <td>[\"1. The type of ambiguity encountered is like...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>1029897539</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>[\"Is it possible to give a transformer custom ...</td>\n",
       "      <td>[\"Yes, it is possible to give a transformer mo...</td>\n",
       "      <td>[\"Yes, it is possible to give a transformer mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>2888250053</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>[\"How to use Poetry to install packages in pyt...</td>\n",
       "      <td>[\"Poetry is a tool for dependency management a...</td>\n",
       "      <td>[\"Poetry is a dependency manager for Python th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a             model_b  \\\n",
       "9754   1051544564    qwen1.5-72b-chat  gpt-4-1106-preview   \n",
       "19106  2049273519  gpt-4-1106-preview    qwen1.5-72b-chat   \n",
       "20511  2199125192    qwen1.5-72b-chat  gpt-4-1106-preview   \n",
       "9565   1029897539  gpt-4-1106-preview    qwen1.5-72b-chat   \n",
       "26870  2888250053  gpt-4-1106-preview    qwen1.5-72b-chat   \n",
       "\n",
       "                                                  prompt  \\\n",
       "9754   [\"\\nread this content. Do not change the conte...   \n",
       "19106  [\"Which is the newest model that also contain ...   \n",
       "20511  [\"Please answer this questions in 8 sentences ...   \n",
       "9565   [\"Is it possible to give a transformer custom ...   \n",
       "26870  [\"How to use Poetry to install packages in pyt...   \n",
       "\n",
       "                                              response_a  \\\n",
       "9754   [\"6. Use AI Writing Tools\\n\\nIncorporating AI ...   \n",
       "19106  [\"I'm sorry, but your question isn't clear. Wh...   \n",
       "20511  [\"1. When a legal description appears clear in...   \n",
       "9565   [\"Yes, it is possible to give a transformer mo...   \n",
       "26870  [\"Poetry is a tool for dependency management a...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "9754   [\"6. Use AI to Your Advantage\\n\\nIn this age o...               1   \n",
       "19106  [\"As an AI, I don't have real-time access to u...               0   \n",
       "20511  [\"1. The type of ambiguity encountered is like...               1   \n",
       "9565   [\"Yes, it is possible to give a transformer mo...               0   \n",
       "26870  [\"Poetry is a dependency manager for Python th...               0   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "9754                0           0  \n",
       "19106               1           0  \n",
       "20511               0           0  \n",
       "9565                1           0  \n",
       "26870               1           0  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's investigate the responses that changed the Top-5 models.\n",
    "mistral_qwen_inds = chatbot_arena_results_with_props[\"indices\"].iloc[2]\n",
    "chatBotArena_noTies.iloc[mistral_qwen_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== prompt 1 ===\n",
      "\n",
      "[\"\\nread this content. Do not change the content written. Add 5 more tips in the same tone of voice\n",
      "and style. \\nhave one be use AI \\n\\nHey freelance writers: Let's talk about writer's block.\\n\\nI\n",
      "know, I know. You don't want to say it out loud. It's like \\\"Voldemort\\\" or actors saying\n",
      "\\\"Macbeth\\\" out loud (that's why they call it \\\"The Scottish Play\\\"). But, like the common cold,\n",
      "writer's block is out there ... and odds are, it's going to get every freelance writer at some\n",
      "point.\\n\\nThe Terror of Writer's Block\\n\\nYou've probably had it happen to you at one time or\n",
      "another. You're sitting at your desk, a cup of coffee or cold beverage nearby, ready to start\n",
      "writing, knocking off those assignments, and adding some zeroes to the bank account. The words are\n",
      "ready to go ... but somehow, someway, they just won't come out. The blank page remains there,\n",
      "looking at you, taunting you.\\n\\nThen the terror starts. \\\"Oh no,\\\" you think. \\\"How long will this\n",
      "last? Will I get paralyzed by writer's block? Is my writing career over? Am I going to have to find\n",
      "a whole new line of work?\\\"\\n\\nIt's a feeling very specific to freelance writers, that mixture of\n",
      "terror and dread that comes with writer's block. However, don't fret. Writer's block isn't\n",
      "permanent. There are plenty of strategies you can employ to get over it and get back on the writing\n",
      "wagon. Let's go through some of them here!\\n\\n5 Strategies to Get Over Writer's Block\\n\\nSo, how can\n",
      "freelance writers get over writer's block? Here are five ways to do it.\\n\\n1. Take a\n",
      "Break\\u00a0\\n\\nTaking time to yourself is ALWAYS a great idea, and in this specific situation, it\n",
      "can be an excellent cure for writer's block. Take a few deep breaths. Take a walk in nature. If you\n",
      "have a reliable meditation application or yoga practice, take some time and do a reset. Hop in your\n",
      "car and go for a drive, even if it's just to the convenience store for a soda or two.\\n\\n2. Write\n",
      "About Something Else\\n\\nIt might be the subject that's blocking you up. Do some experimenting to\n",
      "find out if it's just what you need to write about that's putting you in the box. Remember the\n",
      "incredible story about the Coen brothers: When they got stuck while writing the movie \\\"Miller's\n",
      "Crossing,\\\" they instead wrote a movie about someone with writer's block. That movie is \\\"Barton\n",
      "Fink,\\\" one of their finest works. Odds are, you probably have another assignment or two coming up\n",
      "OR your own type of creative writing project in a drawer somewhere. Try to shift your focus a\n",
      "little, and see if that prompts anything.\\n\\n3. Change Your Environment\\u00a0\\n\\nEvery writer runs\n",
      "the risk of letting their environment get to them. If you're one of the many writers that do their\n",
      "work in the same place every day (a desk, a couch, etc.), try to switch things up. Go to a coffee\n",
      "shop (rules and regulations pending, of course), try a different part of your home, or move to a\n",
      "professional environment (like a rented workspace) for the day to get your brain working. You might\n",
      "be surprised what breaks the dam open.\\n\\n4. Defeat the Blank Page\\n\\nThe blank page is the most\n",
      "intimidating thing in the world for a writer. It's full of promise and potential, of course, but\n",
      "it's also extremely scary \\u2014 there's no one else who can fill it in! It's all on you, after all.\n",
      "So, fill that blank page in with something. Put in a bit of writing that inspires you. Put in a\n",
      "quote that you like. Hey, even just smash your fingers on the keyboard and fill the blank screen\n",
      "with absolute nonsense. After that, you can say that you started writing something, even if you\n",
      "technically have written nothing toward the actual assignment. That might help!\\n\\n5. Remind\n",
      "Yourself That You're Awesome\\n\\nFreelance writers, remind yourself that that's exactly what you are.\n",
      "You're a writer. That's a powerful thing. A lot of people want to say that they're writers. Very few\n",
      "of them actually are. You've gotten paid to put words down on paper (or the internet). That's\n",
      "exceedingly rare. You're valuable, smart, intelligent, and an excellent writer. Keep saying that to\n",
      "yourself. Peruse through a few assignments that got you kudos or that made you proud. Then, sit down\n",
      "and realize that \\\"this too shall pass.\\\"\\n\\nNow, start writing!\\n\\nGetting Started With\n",
      "Scripted\\n\\nIf you're one of the many freelance writers who have gone through writer's block (and\n",
      "come out on the other side), or even if you're one of the lucky ones to avoid it over the years,\n",
      "it's time to join Scripted! Scripted boasts the best community for writers on the web, with\n",
      "excellent rates, wonderful topics to write about, and much more.\"]\n",
      "\n",
      "=== prompt 2 ===\n",
      "\n",
      "[\"Which is the newest model that also contain data of 2023?\"]\n",
      "\n",
      "=== prompt 3 ===\n",
      "\n",
      "[\"Please answer this questions in 8 sentences and do not use wording indicative of AI\\n\\n1.You are\n",
      "provided with a legal description that seems to make sense when you initially read\\nit but once you\n",
      "arrive at the site it no longer does. What type of ambiguity have you\\nencountered? How would you go\n",
      "about conducting retracement work with an ambiguous\\ndescription? What evidence should be\n",
      "collected?\\n2. Original monumentation is generally treated as authoritative. Why was this not the\n",
      "case in\\nRichmond Hill Furriers v. Clarissa Developments?\\n3. What is meant by the terms\n",
      "\\u201cextrinsic evidence\\u201d and \\u201cparol evidence\\u201d? Provide an example\\nof each and\n",
      "explain the circumstances under which they could be used or not be used by a\\ncourt in deciding on a\n",
      "disputed boundary line.\\n4. Under what circumstances does evidence of the subdivider\\u2019s\n",
      "intention become important?\\nWhat types of evidence did the court use in Home Bank of Canada v.\n",
      "Might Directories and\\nOvens v. Davidson to show a subdivider\\u2019s intention in their\n",
      "decisions?\\n2\\n5. Excerpts from the decision in Doyle v. Macdonald are included in the Annotated\n",
      "Readings as\\nan example of a dispute involving differing interpretations of a metes and\n",
      "bounds\\ndescription in a deed. What are the key \\u201ctake-aways\\u201d from this case? Why is it\n",
      "an\\ninstructive example in the application of key principles\"]\n",
      "\n",
      "=== prompt 4 ===\n",
      "\n",
      "[\"Is it possible to give a transformer custom embeddings?\"]\n",
      "\n",
      "=== prompt 5 ===\n",
      "\n",
      "[\"How to use Poetry to install packages in python\"]\n"
     ]
    }
   ],
   "source": [
    "# MIS: prompts.\n",
    "# for prompt in chatBotArena_noTies.iloc[gpt4top2_inds]['prompt']:\n",
    "#     print(prompt)\n",
    "import textwrap\n",
    "for i, prompt in enumerate(chatBotArena_noTies.loc[mistral_qwen_inds]['prompt']):\n",
    "    print(f\"\\n=== prompt {i+1} ===\\n\")\n",
    "    print(textwrap.fill(prompt, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Response 1 ===\n",
      "\n",
      "[\"6. Use AI Writing Tools\\n\\nIncorporating AI writing tools can occasionally help break the creative\n",
      "gridlock. There are various AI assistants that can generate prompts, suggest sentences, or even\n",
      "complete paragraphs for you. Of course, you'll want to maintain your unique voice and edit AI-\n",
      "generated content, but it's a useful starting point to overcome writer's block. It can spark new\n",
      "ideas or simply provide a gentle nudge to get your creative juices flowing.\\n\\n7. Engage in Physical\n",
      "Exercise\\n\\nPhysical activity can help clear your mind and boost your energy levels. Go for a run,\n",
      "hit the gym, or do a brief workout session. Exercise releases endorphins that can improve your mood\n",
      "and stimulate your brain, making it easier to overcome writer's block. Plus, you'll feel refreshed\n",
      "and ready to tackle your writing once you're done.\\n\\n8. Set Realistic Writing Goals\\n\\nSometimes,\n",
      "the pressure of a looming deadline or an overly ambitious goal can contribute to writer's block.\n",
      "Break your writing tasks into smaller, manageable chunks. Set realistic daily or hourly word count\n",
      "goals, and reward yourself for reaching each milestone. This approach can help alleviate stress and\n",
      "make the writing process feel more achievable.\\n\\n9. Connect with Fellow Writers\\n\\nTalking to other\n",
      "writers can provide valuable insights and encouragement. Join a writing group or attend a virtual\n",
      "workshop. Share your struggles with writer's block and listen to how others have dealt with it. You\n",
      "might find a new approach or simply gain comfort from knowing you're not alone.\\n\\n10. Embrace\n",
      "Imperfection\\n\\nRemember that your first draft doesn't have to be perfect. In fact, it's okay if\n",
      "it's terrible! The beauty of writing is in the editing process. Just start writing anything that\n",
      "comes to mind, even if it seems nonsensical or irrelevant. The act of getting words down on the page\n",
      "can often lead to a breakthrough. You can always revise and polish later, but the most important\n",
      "thing is to get started.\\n\\nWith these additional strategies, you'll be better equipped to conquer\n",
      "writer's block and continue thriving in your freelance writing career. Happy writing!\"]\n",
      "\n",
      "=== Response 2 ===\n",
      "\n",
      "[\"I'm sorry, but your question isn't clear. When you ask about the \\\"newest model that also contains\n",
      "data of 2023,\\\" I need more context to provide you with an accurate answer. Are you referring to a\n",
      "specific type of product or technology, such as a car, a smartphone, a computer, or something else?\n",
      "Please provide more details so I can assist you effectively.\"]\n",
      "\n",
      "=== Response 3 ===\n",
      "\n",
      "[\"1. When a legal description appears clear initially but becomes confusing at the site, it\n",
      "indicates an issue of latent ambiguity. Retracement work with such a description requires careful\n",
      "examination of surrounding landmarks, historical records, and surveys. To proceed, one would consult\n",
      "old deeds, plat maps, and possibly consult with experts like land surveyors. Gathering evidence like\n",
      "original survey notes, photographs, and witness testimonials from neighboring landowners can help\n",
      "clarify the intended boundaries.\\n2. In Richmond Hill Furriers v. Clarissa Developments, original\n",
      "monumentation was not treated as authoritative due to the presence of a latent ambiguity. The court\n",
      "found that the developer's intentions were not clear, and the physical evidence on the ground\n",
      "contradicted the survey, necessitating a reevaluation of the property lines.\\n3. Extrinsic evidence\n",
      "refers to information outside the legal document that can help clarify its meaning, such as witness\n",
      "testimony or surrounding circumstances at the time of the deed. Parol evidence, on the other hand,\n",
      "is oral evidence or testimony that explains the context of a written contract. An example of\n",
      "extrinsic evidence could be a diary entry describing the intent behind a property transfer. Parol\n",
      "evidence might be a witness's recollection of a conversation between the parties involved. Courts\n",
      "may allow these types of evidence when the document's meaning is unclear or disputed, but they may\n",
      "not be considered if the contract is deemed unambiguous.\\n4. The subdivider's intention becomes\n",
      "crucial when there's ambiguity in the description or when the physical monuments don't align with\n",
      "the legal description. In Home Bank of Canada v. Might Directories, the court looked at the layout\n",
      "of streets and lots to infer the subdivider's intent. In Ovens v. Davidson, the court considered the\n",
      "logical arrangement of properties and the developer's plans to determine the boundary. These cases\n",
      "demonstrate that courts can use various types of evidence, including deeds, surveys, and development\n",
      "plans, to understand the subdivider's original purpose.\\n5. Doyle v. Macdonald showcases the\n",
      "importance of precise language and the challenges in interpreting metes and bounds descriptions. Key\n",
      "takeaways include the need for clear communication, the significance of landmarks, and the court's\n",
      "reliance on the intent of the original parties. This case serves as an instructive example because\n",
      "it highlights the potential for disputes when descriptions are imprecise, emphasizing the importance\n",
      "of accurate and detailed boundary descriptions in property transactions.\"]\n",
      "\n",
      "=== Response 4 ===\n",
      "\n",
      "[\"Yes, it is possible to give a transformer model custom embeddings. Transformer models typically\n",
      "use an embedding layer at the input to convert token IDs into vector representations. These\n",
      "embeddings can be either trained from scratch along with the model or initialized with pre-trained\n",
      "embeddings such as word2vec, GloVe, or fastText.\\n\\nTo use custom embeddings in a transformer model,\n",
      "you would typically follow these steps:\\n\\n1. **Prepare Custom Embeddings**: First, you'll need to\n",
      "have your custom embeddings ready. These could be embeddings you've trained yourself or embeddings\n",
      "from another source that you want to use with your transformer model.\\n\\n2. **Initialize Embedding\n",
      "Layer**: When building your transformer model, you would initialize the embedding layer with your\n",
      "custom embeddings. This usually involves replacing the default initialization with your pre-trained\n",
      "embeddings. For example, in PyTorch, you might do something like this:\\n\\n```python\\nimport\n",
      "torch\\nfrom torch.nn import Embedding\\n\\n# Assuming you have a pre-trained embedding matrix\n",
      "'pretrained_embeddings'\\n# with shape (vocab_size, embedding_dim)\\nembedding_layer =\n",
      "Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\\nembedding_layer.weight.data.copy_\n",
      "(torch.from_numpy(pretrained_embeddings))\\n```\\n\\n3. **Freeze Embeddings (Optional)**: Depending on\n",
      "your use case, you may want to freeze the embeddings, which means they will not be updated during\n",
      "training. This is common when using pre-trained embeddings that are already tuned for your task. To\n",
      "freeze the embeddings in PyTorch, you would do:\\n\\n```python\\nembedding_layer.weight.requires_grad =\n",
      "False\\n```\\n\\n4. **Integrate with Transformer**: Once you have your embedding layer set up, you can\n",
      "integrate it into your transformer model architecture. Make sure to replace the default embedding\n",
      "layer with your custom one.\\n\\n5. **Train or Fine-Tune**: You can now proceed to train or fine-tune\n",
      "your transformer model with the custom embeddings. If you've chosen to freeze the embeddings, only\n",
      "the rest of the model's parameters will be updated.\\n\\nIt's worth noting that the transformer\n",
      "architecture is designed to work with embeddings of a specific dimension (the model's hidden size).\n",
      "So, your custom embeddings need to match that dimension, or you will need to add a linear layer to\n",
      "project them to the correct size.\\n\\nAlso, keep in mind that when dealing with models like BERT or\n",
      "GPT, the embedding layer is often more complex, including position embeddings and token type\n",
      "embeddings in addition to word embeddings. You would need to ensure that your custom embeddings are\n",
      "compatible with the model's architecture.\"]\n",
      "\n",
      "=== Response 5 ===\n",
      "\n",
      "[\"Poetry is a tool for dependency management and packaging in Python. It allows you to declare the\n",
      "libraries your project depends on and it will manage (install\\/update) them for you. To use Poetry\n",
      "to install packages, you need to have Poetry itself installed. If you haven't already installed\n",
      "Poetry, you can do so using the following command:\\n\\n```bash\\ncurl -sSL https:\\/\\/install.python-\n",
      "poetry.org | python3 -\\n```\\n\\nOr, for Windows PowerShell:\\n\\n```powershell\\n(Invoke-WebRequest -Uri\n",
      "https:\\/\\/install.python-poetry.org -UseBasicParsing).Content | py -\\n```\\n\\nPlease ensure that you\n",
      "have `python` and `curl` installed on your system before running these commands. After installing\n",
      "Poetry, follow these steps to use it for managing dependencies:\\n\\n1. **Initialize a new project\n",
      "with Poetry** (if you haven't already):\\n   ```bash\\n   poetry new my-project\\n   ```\\n   Replace\n",
      "`my-project` with the name of your project. This will create a new directory with some basic\n",
      "structure and a `pyproject.toml` file, which is used by Poetry to manage dependencies.\\n\\n2. **Add a\n",
      "dependency**:\\n   To add a new package to your project, use the `add` command:\\n   ```bash\\n\n",
      "poetry add package-name\\n   ```\\n   Replace `package-name` with the name of the package you want to\n",
      "install. Poetry will resolve the dependencies, download the package, and update the `pyproject.toml`\n",
      "and `poetry.lock` files accordingly.\\n\\n3. **Install dependencies**:\\n   If you have a\n",
      "`pyproject.toml` file with defined dependencies, you can install all of them at once using:\\n\n",
      "```bash\\n   poetry install\\n   ```\\n   This command will install all the dependencies specified in\n",
      "your `pyproject.toml` file, based on the versions locked in the `poetry.lock` file to ensure\n",
      "repeatability.\\n\\n4. **Update a dependency**:\\n   To update a specific package, use the `update`\n",
      "command:\\n   ```bash\\n   poetry update package-name\\n   ```\\n   Replace `package-name` with the name\n",
      "of the package you want to update. To update all packages, just run `poetry update` without\n",
      "specifying a package name.\\n\\n5. **Remove a dependency**:\\n   To remove a package that you no longer\n",
      "need, use the `remove` command:\\n   ```bash\\n   poetry remove package-name\\n   ```\\n   Replace\n",
      "`package-name` with the name of the package you want to remove.\\n\\nRemember to activate the virtual\n",
      "environment that Poetry has created for your project before running your Python application. You can\n",
      "do this by executing `poetry shell` or by using `poetry run python yourscript.py` to run your script\n",
      "within the virtual environment without manually activating it.\"]\n"
     ]
    }
   ],
   "source": [
    "# MIS: Answer ModelA.\n",
    "# for response_A in chatBotArena_noTies.iloc[gpt4top2_inds]['response_a']:\n",
    "#     print(response_A)\n",
    "import textwrap\n",
    "\n",
    "for i, response_a in enumerate(chatBotArena_noTies.loc[mistral_qwen_inds]['response_a']):\n",
    "    print(f\"\\n=== Response {i+1} ===\\n\")\n",
    "    print(textwrap.fill(response_a, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Response 1 ===\n",
      "\n",
      "[\"6. Use AI to Your Advantage\\n\\nIn this age of technology, leverage the power of AI to overcome\n",
      "writer's block. AI writing tools can provide prompts, continue a thought, or even help outline your\n",
      "piece. It's like having a brainstorming buddy at your fingertips, one who's available 24\\/7 and\n",
      "doesn't mind you bouncing ideas off of them, no matter how rough they might be. Just type in a\n",
      "sentence or a theme, and let the artificial intelligence give you a nudge in the right direction.\n",
      "Remember, it's not about replacing your creativity but enhancing it.\\n\\n7. Set Small, Achievable\n",
      "Goals\\n\\nSometimes writer's block stems from feeling overwhelmed by the size of the project. Break\n",
      "it down into small, manageable pieces. Set a goal for a paragraph, a page, or maybe just a great\n",
      "opening sentence. Achieving these smaller goals can give you a sense of progress and help build\n",
      "momentum. As you tick off these mini milestones, the larger project won't seem so daunting.\\n\\n8.\n",
      "Engage in Creative Cross-Training\\n\\nJust like athletes cross-train to improve overall performance,\n",
      "writers can benefit from flexing different creative muscles. Try your hand at poetry, flash fiction,\n",
      "or even doodling. Engage in a different form of storytelling to stimulate your mind. These creative\n",
      "exercises can unlock new ways of thinking and help you approach your writing blocks from fresh\n",
      "angles.\\n\\n9. Collaborate with Other Writers\\n\\nReach out to your network of fellow scribes.\n",
      "Sometimes, discussing your project with another writer can provide the breakthrough you need.\n",
      "Collaborative brainstorming sessions, writing groups, or even online forums can offer new\n",
      "perspectives and insights that help you break through the block. Plus, it's always comforting to\n",
      "know you're not alone in your struggles.\\n\\n10. Embrace Free Writing\\n\\nSet a timer for 10-15\n",
      "minutes and just write. Don't worry about grammar, structure, or even making sense. Just let the\n",
      "words flow without judgment or the pressure of your assignment. This free writing exercise can act\n",
      "as a warm-up for your brain, loosening up the mental muscles and often leading to unexpected ideas\n",
      "that you can refine and use in your actual writing work.\"]\n",
      "\n",
      "=== Response 2 ===\n",
      "\n",
      "[\"As an AI, I don't have real-time access to updates or the ability to browse the internet for the\n",
      "most recent information. My knowledge is based on the data I was trained on, which is up until 2021.\n",
      "Therefore, I cannot tell you about the newest model that contains data from 2023. For the most up-\n",
      "to-date information, I would recommend checking the official websites or announcements from major\n",
      "technology companies or AI research institutions.\"]\n",
      "\n",
      "=== Response 3 ===\n",
      "\n",
      "[\"1. The type of ambiguity encountered is likely a latent ambiguity, where the description seems\n",
      "clear on paper but is problematic when applied to the physical location. To conduct retracement work\n",
      "with an ambiguous description, one would start by gathering all available documents related to the\n",
      "property, including the original deed, any maps or surveys, and prior conveyances. Next, one would\n",
      "assess physical evidence on the site, such as existing monuments, fences, or natural landmarks.\n",
      "Additionally, historical evidence, like old photographs or witness testimonies, could provide\n",
      "insights. The evidence collected should corroborate the written description and clarify the original\n",
      "intent.\\n\\n2. In Richmond Hill Furriers v. Clarissa Developments, original monumentation was not\n",
      "treated as authoritative because the monuments did not reflect the true intent of the parties at the\n",
      "time of the original conveyance. The court may have found that the monuments were misplaced or\n",
      "inaccurately represented the legal description of the property. This case illustrates that while\n",
      "original monuments are generally given significant weight, their authority can be challenged if\n",
      "there is compelling evidence that they do not accurately represent the agreed-upon boundaries.\\n\\n3.\n",
      "\\\"Extrinsic evidence\\\" refers to any evidence not contained within the document itself, such as\n",
      "witness testimony, maps, or other documents that help interpret the document. For example, a witness\n",
      "explaining the intention behind a written contract. \\\"Parol evidence\\\" is verbal evidence that is\n",
      "not included in the written contract. An example would be a verbal agreement that precedes or\n",
      "accompanies a written contract. Courts typically do not allow parol evidence to contradict or alter\n",
      "a written agreement, but it may be used if the written contract is ambiguous or incomplete, or to\n",
      "demonstrate fraud or a mistake.\\n\\n4. Evidence of the subdivider's intention becomes important when\n",
      "there is ambiguity or dispute about the meaning of the subdivision plan or associated documents. In\n",
      "Home Bank of Canada v. Might Directories, the court considered the wording in advertising materials\n",
      "to interpret the subdivider's intention. In Ovens v. Davidson, testimony from the subdivider was\n",
      "used to clarify the intent behind the subdivision's boundaries. These types of evidence help courts\n",
      "determine how the original subdivider intended to divide the property.\\n\\n5. The key takeaways from\n",
      "Doyle v. Macdonald include the importance of following the original intent in the deed's metes and\n",
      "bounds description and the necessity of considering both the language of the deed and the physical\n",
      "circumstances at the time of the conveyance. The case is instructive in demonstrating how courts\n",
      "resolve disputes involving ambiguous descriptions by interpreting the deed within its historical\n",
      "context, giving effect to the parties' intentions, and using extrinsic evidence to inform their\n",
      "understanding of the property's physical features as they existed when the deed was executed.\"]\n",
      "\n",
      "=== Response 4 ===\n",
      "\n",
      "[\"Yes, it is possible to give a transformer model custom embeddings. In fact, this is a common\n",
      "practice when fine-tuning pre-trained transformer models for specific tasks.\\n\\nWhen you work with a\n",
      "pre-trained transformer model, such as BERT, GPT, or RoBERTa, the model already has an embedding\n",
      "layer that converts input tokens into dense vectors. These embeddings are learned during the pre-\n",
      "training phase on a large corpus of text. However, you can customize these embeddings in two main\n",
      "ways:\\n\\n1. **Fixed embeddings**: If you have pre-existing embeddings for your input tokens, you can\n",
      "use them as a starting point. You can replace the initial embedding layer with your custom\n",
      "embeddings, keeping them fixed during fine-tuning. This approach is useful if you have domain-\n",
      "specific embeddings or want to incorporate external knowledge. However, keep in mind that the rest\n",
      "of the model will not be able to update these embeddings during training.\\n\\n2. **Fine-tunable\n",
      "embeddings**: In most cases, when you fine-tune a transformer model, you allow the entire model,\n",
      "including the embedding layer, to be updated during training. This means that the model can learn\n",
      "task-specific embeddings based on your input data. You can initialize the embedding layer with your\n",
      "custom embeddings, and the model will adjust them during the fine-tuning process.\\n\\nTo implement\n",
      "custom embeddings, you'll need to modify the model's code or use a library that supports this\n",
      "feature. For instance, if you're using Hugging Face's `Transformers` library in Python, you can\n",
      "create a custom `PreTrainedModel` subclass, load your pre-trained transformer, and replace the\n",
      "embedding layer with your custom one. Alternatively, you can use the `from_pretrained` method and\n",
      "pass your custom embeddings as an argument.\\n\\nHere's an example using Hugging Face's `Transformers`\n",
      "library:\\n\\n```python\\nfrom transformers import BertModel, BertTokenizer, BertConfig\\n\\n# Load pre-\n",
      "trained model and tokenizer\\nmodel = BertModel.from_pretrained('bert-base-uncased')\\ntokenizer =\n",
      "BertTokenizer.from_pretrained('bert-base-uncased')\\n\\n# Create custom embeddings (this is a\n",
      "placeholder, replace with your actual embeddings)\\ncustom_embeddings =\n",
      "torch.randn((tokenizer.vocab_size, model.config.hidden_size))\\n\\n# Replace the model's embedding\n",
      "layer with custom embeddings\\nmodel.bert.embeddings.word_embeddings =\n",
      "nn.Embedding.from_pretrained(custom_embeddings, freeze=False)\\n\\n# Now, the model is ready to be\n",
      "fine-tuned with your custom embeddings\\n```\\n\\nRemember to adjust the code according to your\n",
      "specific use case and custom embeddings.\"]\n",
      "\n",
      "=== Response 5 ===\n",
      "\n",
      "[\"Poetry is a dependency manager for Python that makes it easy to manage project dependencies and\n",
      "create self-contained virtual environments. To use Poetry to install packages in a Python project,\n",
      "follow these steps:\\n\\n1. **Install Poetry**:\\n   First, you need to install Poetry on your system.\n",
      "You can do this by running the following command (you may need administrative privileges):\\n\\n   For\n",
      "Linux\\/macOS:\\n   ```\\n   curl -sSL https:\\/\\/raw.githubusercontent.com\\/python-\n",
      "poetry\\/poetry\\/master\\/get-poetry.py | python -\\n   ```\\n\\n   For Windows:\\n   ```\\n   python -m\n",
      "pip install --upgrade poetry\\n   ```\\n\\n2. **Create a new project or navigate to an existing\n",
      "one**:\\n   If you're starting a new project, create a new directory for it and navigate to that\n",
      "directory in your terminal. If you already have an existing project, navigate to the project's root\n",
      "directory.\\n\\n3. **Initialize Poetry**:\\n   Run the following command to initialize a new Poetry\n",
      "project and create a `pyproject.toml` file:\\n   ```\\n   poetry init\\n   ```\\n\\n   Follow the prompts\n",
      "to set up your project's dependencies and requirements.\\n\\n4. **Add a package**:\\n   To install a\n",
      "new package, use the `poetry add` command followed by the package name. For example, to install the\n",
      "`requests` package:\\n   ```\\n   poetry add requests\\n   ```\\n\\n   This command will add the package\n",
      "to your `pyproject.toml` file and install it in the project's virtual environment.\\n\\n5. **Update an\n",
      "existing package**:\\n   If you want to update a package to its latest version, use the `poetry\n",
      "update` command followed by the package name (optional):\\n   ```\\n   poetry update requests\\n\n",
      "```\\n\\n   If you don't specify a package name, it will update all the packages in your\n",
      "project.\\n\\n6. **Lock dependencies**:\\n   To create a `poetry.lock` file, which ensures that the\n",
      "exact versions of dependencies are used across different environments, run:\\n   ```\\n   poetry\n",
      "lock\\n   ```\\n\\n7. **Activate the virtual environment**:\\n   To work with the installed packages in\n",
      "the project, activate the virtual environment:\\n   - Linux\\/macOS:\\n     ```\\n     poetry shell\\n\n",
      "```\\n\\n   - Windows:\\n     ```\\n     .venv\\\\Scripts\\\\activate\\n     ```\\n\\n   Now you're inside the\n",
      "virtual environment, and you can run your Python scripts or import the installed packages.\\n\\n8.\n",
      "**Exit the virtual environment**:\\n   When you're done, exit the virtual environment by typing\n",
      "`exit` in the terminal.\\n\\nRemember that Poetry manages the dependencies locally for each project,\n",
      "so you don't need to worry about conflicts between projects.\"]\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for i, response_b in enumerate(chatBotArena_noTies.loc[mistral_qwen_inds]['response_b']):\n",
    "    print(f\"\\n=== Response {i+1} ===\\n\")\n",
    "    print(textwrap.fill(response_b, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
