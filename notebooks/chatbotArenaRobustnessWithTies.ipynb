{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.data_script import make_BT_design_matrix\n",
    "from package.RankAMIP.logistic import LogisticAMIP\n",
    "from package.RankAMIP.logistic import find_closest_matchups\n",
    "from package.RankAMIP.logistic import isRankingRobust\n",
    "from package.RankAMIP.plot_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is ChatBot Arena Data Robust? (Version with Ties, As Implementated on Live Chatbot Arena)\n",
    "https://colab.research.google.com/drive/1KdwokPjirkTmpO_P1WByFNFiqxWQquwH#scrollTo=mSizG3Pzglte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets from https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"lmarena-ai/arena-human-preference-55k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
      "        num_rows: 57477\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# inspect the available splits\n",
    "print(ds)  \n",
    "# grab the ‘train’ split\n",
    "train = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Weighted Dataset (duplicate wins/losses, and add split the ties -- A wins one, B wins one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>preference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>862324</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[\"Write me a poem in urdu in the style of Iqba...</td>\n",
       "      <td>[\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...</td>\n",
       "      <td>[\"In the realm of selflessness dwells the true...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>862324</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[\"Write me a poem in urdu in the style of Iqba...</td>\n",
       "      <td>[\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...</td>\n",
       "      <td>[\"In the realm of selflessness dwells the true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>933555</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>[\"Mary has 6 others siblings named Monday, Tue...</td>\n",
       "      <td>[\"Hello! I'm happy to help you with your quest...</td>\n",
       "      <td>[\"The last child's name is likely Saturday.\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>933555</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>[\"Mary has 6 others siblings named Monday, Tue...</td>\n",
       "      <td>[\"Hello! I'm happy to help you with your quest...</td>\n",
       "      <td>[\"The last child's name is likely Saturday.\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1256092</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[\"Write a python code that calculates sum of 5...</td>\n",
       "      <td>[\"Here is the python code that calculates the ...</td>\n",
       "      <td>[\"Here is a Python code that calculates the su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1256092</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[\"Write a python code that calculates sum of 5...</td>\n",
       "      <td>[\"Here is the python code that calculates the ...</td>\n",
       "      <td>[\"Here is a Python code that calculates the su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1440765</td>\n",
       "      <td>llama2-70b-steerlm-chat</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>[\"Can you explain what the Cypher Query Langua...</td>\n",
       "      <td>[\"The Cypher Query Language is a declarative l...</td>\n",
       "      <td>[\"Certainly! The Cypher Query Language, often ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1440765</td>\n",
       "      <td>llama2-70b-steerlm-chat</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>[\"Can you explain what the Cypher Query Langua...</td>\n",
       "      <td>[\"The Cypher Query Language is a declarative l...</td>\n",
       "      <td>[\"Certainly! The Cypher Query Language, often ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  model_a             model_b  \\\n",
       "4     65089       gpt-3.5-turbo-0613      mistral-medium   \n",
       "5     65089       gpt-3.5-turbo-0613      mistral-medium   \n",
       "28   862324               vicuna-13b           koala-13b   \n",
       "29   862324               vicuna-13b           koala-13b   \n",
       "36   933555         llama-2-13b-chat    claude-instant-1   \n",
       "37   933555         llama-2-13b-chat    claude-instant-1   \n",
       "40  1256092               claude-2.1          vicuna-13b   \n",
       "41  1256092               claude-2.1          vicuna-13b   \n",
       "44  1440765  llama2-70b-steerlm-chat  gpt-4-0125-preview   \n",
       "45  1440765  llama2-70b-steerlm-chat  gpt-4-0125-preview   \n",
       "\n",
       "                                               prompt  \\\n",
       "4   [\"explain function calling. how would you call...   \n",
       "5   [\"explain function calling. how would you call...   \n",
       "28  [\"Write me a poem in urdu in the style of Iqba...   \n",
       "29  [\"Write me a poem in urdu in the style of Iqba...   \n",
       "36  [\"Mary has 6 others siblings named Monday, Tue...   \n",
       "37  [\"Mary has 6 others siblings named Monday, Tue...   \n",
       "40  [\"Write a python code that calculates sum of 5...   \n",
       "41  [\"Write a python code that calculates sum of 5...   \n",
       "44  [\"Can you explain what the Cypher Query Langua...   \n",
       "45  [\"Can you explain what the Cypher Query Langua...   \n",
       "\n",
       "                                           response_a  \\\n",
       "4   [\"Function calling is the process of invoking ...   \n",
       "5   [\"Function calling is the process of invoking ...   \n",
       "28  [\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...   \n",
       "29  [\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...   \n",
       "36  [\"Hello! I'm happy to help you with your quest...   \n",
       "37  [\"Hello! I'm happy to help you with your quest...   \n",
       "40  [\"Here is the python code that calculates the ...   \n",
       "41  [\"Here is the python code that calculates the ...   \n",
       "44  [\"The Cypher Query Language is a declarative l...   \n",
       "45  [\"The Cypher Query Language is a declarative l...   \n",
       "\n",
       "                                           response_b  winner_model_a  \\\n",
       "4   [\"Function calling is the process of invoking ...               0   \n",
       "5   [\"Function calling is the process of invoking ...               1   \n",
       "28  [\"In the realm of selflessness dwells the true...               0   \n",
       "29  [\"In the realm of selflessness dwells the true...               1   \n",
       "36      [\"The last child's name is likely Saturday.\"]               0   \n",
       "37      [\"The last child's name is likely Saturday.\"]               1   \n",
       "40  [\"Here is a Python code that calculates the su...               0   \n",
       "41  [\"Here is a Python code that calculates the su...               1   \n",
       "44  [\"Certainly! The Cypher Query Language, often ...               0   \n",
       "45  [\"Certainly! The Cypher Query Language, often ...               1   \n",
       "\n",
       "    winner_model_b  winner_tie  preference_id  \n",
       "4                0           1              3  \n",
       "5                0           1              3  \n",
       "28               0           1             15  \n",
       "29               0           1             15  \n",
       "36               0           1             19  \n",
       "37               0           1             19  \n",
       "40               0           1             21  \n",
       "41               0           1             21  \n",
       "44               0           1             23  \n",
       "45               0           1             23  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Add a preference_id column.\n",
    "df['preference_id'] = np.arange(1, len(df) + 1)\n",
    "\n",
    "# Step 2: Split into ties and non-ties\n",
    "df_ties = df[df['winner_tie'] == 1].copy()\n",
    "df_non_ties = df[df['winner_tie'] == 0].copy()\n",
    "\n",
    "# Step 3: Duplicate non-tie rows\n",
    "df_non_ties_duplicated = pd.concat([df_non_ties, df_non_ties], ignore_index=True)\n",
    "\n",
    "# Step 4: Flip winner_model_a for tie rows\n",
    "df_ties_flipped = df_ties.copy()\n",
    "df_ties_flipped['winner_model_a'] = 1 - df_ties_flipped['winner_model_a']\n",
    "\n",
    "# Tag each version for sorting\n",
    "df_ties['version'] = 0  # Original tie\n",
    "df_ties_flipped['version'] = 1  # Flipped tie\n",
    "\n",
    "# Combine ties with proper grouping\n",
    "df_ties_combined = pd.concat([df_ties, df_ties_flipped], ignore_index=True)\n",
    "\n",
    "# Step 5: Combine all rows\n",
    "df_non_ties_duplicated['version'] = -1  # So non-ties always come first\n",
    "df_weighted = pd.concat([df_non_ties_duplicated, df_ties_combined], ignore_index=True)\n",
    "\n",
    "# Step 6: Sort by preference_id and version to ensure tie + flipped_tie adjacency\n",
    "df_weighted = df_weighted.sort_values(by=['preference_id', 'version']).reset_index(drop=True)\n",
    "\n",
    "# (Optional) Drop 'version' if no longer needed\n",
    "df_weighted = df_weighted.drop(columns='version')\n",
    "\n",
    "df_weighted[df_weighted['winner_tie'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weighted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique model names: 64\n"
     ]
    }
   ],
   "source": [
    "# get the unique names in both columns\n",
    "model_a_names = df_weighted['model_a'].unique()\n",
    "model_b_names = df_weighted['model_b'].unique()\n",
    "# combine the two arrays and get the unique names\n",
    "model_names = np.unique(np.concatenate((model_a_names, model_b_names)))\n",
    "# print the number of unique model names\n",
    "print(f\"Number of unique model names: {len(model_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a         model_b  winner_model_a\n",
       "0  gpt-4-1106-preview      gpt-4-0613               1\n",
       "1  gpt-4-1106-preview      gpt-4-0613               1\n",
       "2           koala-13b      gpt-4-0613               0\n",
       "3           koala-13b      gpt-4-0613               0\n",
       "4  gpt-3.5-turbo-0613  mistral-medium               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawBT = df_weighted[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a              model_b  winner_model_a\n",
       "0  gpt-4-1106-preview           gpt-4-0613               1\n",
       "1           koala-13b           gpt-4-0613               0\n",
       "2  gpt-3.5-turbo-0613       mistral-medium               0\n",
       "3    llama-2-13b-chat  mistral-7b-instruct               1\n",
       "4           koala-13b   gpt-3.5-turbo-0314               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawBT_orig = df[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Top-k Robustness Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphaN: 2\n",
      "alphaN: 3\n",
      "alphaN: 4\n",
      "alphaN: 2\n",
      "alphaN: 3\n",
      "alphaN: 4\n",
      "alphaN: 5\n",
      "alphaN: 6\n",
      "alphaN: 7\n",
      "alphaN: 8\n",
      "alphaN: 9\n",
      "alphaN: 10\n",
      "alphaN: 11\n",
      "alphaN: 12\n",
      "alphaN: 13\n",
      "alphaN: 14\n",
      "alphaN: 15\n",
      "alphaN: 16\n",
      "alphaN: 17\n",
      "alphaN: 18\n",
      "alphaN: 19\n",
      "alphaN: 20\n",
      "alphaN: 21\n",
      "alphaN: 22\n",
      "alphaN: 23\n",
      "alphaN: 24\n",
      "alphaN: 25\n",
      "alphaN: 26\n",
      "alphaN: 2\n",
      "alphaN: 3\n",
      "alphaN: 4\n",
      "alphaN: 5\n",
      "alphaN: 6\n",
      "alphaN: 7\n",
      "alphaN: 8\n",
      "alphaN: 9\n",
      "alphaN: 10\n",
      "alphaN: 11\n",
      "alphaN: 12\n",
      "alphaN: 13\n",
      "alphaN: 14\n",
      "alphaN: 15\n",
      "alphaN: 16\n",
      "alphaN: 17\n",
      "alphaN: 18\n",
      "alphaN: 2\n",
      "alphaN: 2\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 3, 5, 10, 20]\n",
    "results = {}\n",
    "for k in ks:\n",
    "    alphaN = 1\n",
    "    chatbotA = -1\n",
    "    while chatbotA == -1:\n",
    "        chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X_dup, y_dup)\n",
    "        results[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)\n",
    "        alphaN += 1\n",
    "        print(f'alphaN: {alphaN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot top-20 models on full chatbot arena.\n",
    "filename_to_save = 'fig/top20_cba.png'\n",
    "plot_title = 'Model Rankings in Chatbot Arena'\n",
    "# plot_bt_scores(X, y, rankings, alphaN, 20, plot_title, filename_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 3): (21,\n",
       "  None,\n",
       "  997.4844821153303,\n",
       "  1001.2768504277008,\n",
       "  array([46259,  3527,  6212])),\n",
       " (3, 25): (6,\n",
       "  41,\n",
       "  50.71912577777253,\n",
       "  -1.216407540959752,\n",
       "  array([35121, 52352, 55829, 42442, 40406,  3483, 20172, 25481, 17355,\n",
       "         13244, 22020,  6887, 22343, 39307, 17575,  5270, 53348, 21912,\n",
       "         52752, 49539, 10429, 39612, 47469,   661, 37846])),\n",
       " (5, 17): (41,\n",
       "  47,\n",
       "  31.472403260684565,\n",
       "  -1.7693612459962704,\n",
       "  array([49509, 49513, 54538, 56334, 29584, 14102, 50133, 55511, 13835,\n",
       "         20425, 27552, 38755, 51339, 27090, 12812, 31461, 27279])),\n",
       " (10, 1): (5, 4, -0.47590682407854246, 0.335368506890088, array([47669])),\n",
       " (20, 1): (29, 48, -3.3594514105587336, 0.27216327930572604, array([38092]))}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the (k, alpha N) pairs that are top-k non-robust.\n",
    "results_nonrobust = {k: v for k, v in results.items() if v[0] != -1}\n",
    "results_nonrobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to pickle\n",
    "with open('ChatbotArenaWithTiesNonrobust.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we inspect the ranking flip between the first- and second-place models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in results.\n",
    "import pickle\n",
    "with open(\"results/ChatbotArenaWithTiesNonrobust.pkl\", \"rb\") as f:\n",
    "    chatBotArenaDataDropped = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292873</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
       "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
       "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "3  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "4  292873          vicuna-13b           gpt-4-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"How can I create a test set for a very rare ...   \n",
       "3  [\"What is the best way to travel from Tel-Aviv...   \n",
       "4  [\"Construct a rap battle, in the style of Epic...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Creating a test set for a very rare category...   \n",
       "3  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "4  [\"[Zeus]\\nYo, it's the king of the gods on the...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"When building a classifier for a very rare c...               1   \n",
       "3  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "4  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           0  \n",
       "3               1           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArena_noTies = pd.read_csv(\"data/chatBotArena_noTies.csv\")\n",
    "chatBotArena_noTies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 evals were dropped to flip model i.d. 16 and i.d. None (the reference model).\n",
    "\n",
    "The name of these models are: \n",
    "('gpt-4-0125-preview', 0: 'gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games between GPT-4-1106 and GPT-4-0125:  134\n"
     ]
    }
   ],
   "source": [
    "## Count number of games between the two models that changed ranks.\n",
    "is_gpt41106_gpt40125 = (\n",
    "    (df['model_a'].str.contains('gpt-4-0125-preview') & df['model_b'].str.contains('gpt-4-1106-preview')) |\n",
    "    (df['model_a'].str.contains('gpt-4-1106-preview') & df['model_b'].str.contains('gpt-4-0125-preview'))\n",
    ")\n",
    "\n",
    "num_gpt41106_gpt40125 = df[is_gpt41106_gpt40125].shape[0]\n",
    "print(\"Number of games between GPT-4-1106 and GPT-4-0125: \", num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                (gpt-4-0613, gpt-4-1106-preview)\n",
       "1                         (gpt-4-0613, koala-13b)\n",
       "2            (gpt-3.5-turbo-0613, mistral-medium)\n",
       "3         (llama-2-13b-chat, mistral-7b-instruct)\n",
       "4                 (gpt-3.5-turbo-0314, koala-13b)\n",
       "                           ...                   \n",
       "57472                      (claude-1, gpt-4-0613)\n",
       "57473              (claude-2.0, llama-2-13b-chat)\n",
       "57474                      (alpaca-13b, claude-1)\n",
       "57475                    (palm-2, tulu-2-dpo-70b)\n",
       "57476    (gemini-pro-dev-api, gpt-4-1106-preview)\n",
       "Name: model_pair, Length: 57477, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model pairs (sorted to group symmetric pairs)\n",
    "df['model_pair'] = df.apply(lambda row: tuple(sorted([row['model_a'], row['model_b']])), axis=1)\n",
    "df['model_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of games per model pair: 45.08\n"
     ]
    }
   ],
   "source": [
    "# Count number of games per model pair\n",
    "pair_counts = df['model_pair'].value_counts()\n",
    "\n",
    "# Compute average\n",
    "average_games_per_pair = pair_counts.mean()\n",
    "print(\"Average number of games per model pair:\", average_games_per_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of games that GPT-4-0125 won:  0.26865671641791045\n"
     ]
    }
   ],
   "source": [
    "# Find the win margin between 'gpt-4-0125-preview' and 'gpt-4-1106-preview'\n",
    "# that is, find all games that are between the two models.\n",
    "dfFlippedRanking = df[is_gpt41106_gpt40125]\n",
    "## Count number of games between that 'gpt-4-0125-preview' won.\n",
    "gpt40125_wins = (\n",
    "    (dfFlippedRanking['model_a'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_a'] == 1) |\n",
    "    (dfFlippedRanking['model_b'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_b'] == 1)\n",
    ")\n",
    "num_gpt40125_wins = dfFlippedRanking[gpt40125_wins].shape[0]\n",
    "print(\"Proportion of games that GPT-4-0125 won: \", num_gpt40125_wins / num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player involvement in dropped matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 3): (21,\n",
       "  None,\n",
       "  -0.004146461890131415,\n",
       "  0.0031921260689085195,\n",
       "  array([46259,  3527,  6212])),\n",
       " (3, 25): (6,\n",
       "  41,\n",
       "  0.17525045894466218,\n",
       "  -0.0030410188523184445,\n",
       "  array([35121, 52352, 55829, 42442, 40406,  3483, 20172, 25481, 17355,\n",
       "         13244, 22020,  6887, 22343, 39307, 17575,  5270, 53348, 21912,\n",
       "         52752, 49539, 10429, 39612, 47469,   661, 37846])),\n",
       " (5, 17): (41,\n",
       "  47,\n",
       "  0.013760738510641968,\n",
       "  -0.004423403115031421,\n",
       "  array([49509, 49513, 54538, 56334, 29584, 14102, 50133, 55511, 13835,\n",
       "         20425, 27552, 38755, 51339, 27090, 12812, 31461, 27279])),\n",
       " (10, 1): (5, 4, 0.000824661678016203, -0.003135680049496492, array([28908])),\n",
       " (20, 1): (29, 48, 0.01478311487693984, -0.01627043204034595, array([53747]))}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArenaDataDropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where either model_a or model_b is one of the specified models\n",
    "exclude_models = ['gpt-4-0125-preview', 'gpt-4-1106-preview']\n",
    "\n",
    "not_gpt_previews = ~(\n",
    "    chatBotArena_noTies['model_a'].isin(exclude_models) |\n",
    "    chatBotArena_noTies['model_b'].isin(exclude_models)\n",
    ")\n",
    "\n",
    "chatBotArena_nogpt = chatBotArena_noTies[not_gpt_previews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33625"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArena_nogpt.shape[0] # run the top-1 procedure on the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wout_gpt_preview = {}\n",
    "k = 1\n",
    "alphaN = 1\n",
    "chatbotA = -1\n",
    "while chatbotA == -1:\n",
    "    chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X, y)\n",
    "    results_wout_gpt_preview[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)\n",
    "    alphaN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player involvement w out in-question matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33625, 61), (33625,))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make design matrix for BT.\n",
    "rawBT_chatBotArena_nogpt = chatBotArena_nogpt[['model_a', 'model_b', 'winner_model_a']]\n",
    "\n",
    "newX, newy, player_to_id = make_BT_design_matrix(rawBT_chatBotArena_nogpt)\n",
    "newX.shape, newy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run logistic regression on X, y\n",
    "gpt_AMIP = LogisticAMIP(newX, newy, fit_intercept=False, penalty=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing alphaN:  1\n",
      "testing alphaN:  2\n",
      "testing alphaN:  3\n",
      "testing alphaN:  4\n",
      "testing alphaN:  5\n",
      "testing alphaN:  6\n",
      "testing alphaN:  7\n",
      "testing alphaN:  8\n",
      "testing alphaN:  9\n",
      "testing alphaN:  10\n",
      "testing alphaN:  11\n",
      "testing alphaN:  12\n",
      "testing alphaN:  13\n",
      "testing alphaN:  14\n",
      "testing alphaN:  15\n",
      "testing alphaN:  16\n",
      "testing alphaN:  17\n",
      "testing alphaN:  18\n",
      "testing alphaN:  19\n",
      "testing alphaN:  20\n",
      "testing alphaN:  21\n",
      "testing alphaN:  22\n",
      "testing alphaN:  23\n",
      "testing alphaN:  24\n",
      "testing alphaN:  25\n",
      "testing alphaN:  26\n",
      "testing alphaN:  27\n",
      "testing alphaN:  28\n",
      "testing alphaN:  29\n",
      "testing alphaN:  30\n",
      "testing alphaN:  31\n",
      "testing alphaN:  32\n",
      "testing alphaN:  33\n",
      "testing alphaN:  34\n",
      "testing alphaN:  35\n",
      "testing alphaN:  36\n",
      "testing alphaN:  37\n",
      "testing alphaN:  38\n",
      "testing alphaN:  39\n",
      "testing alphaN:  40\n",
      "testing alphaN:  41\n",
      "testing alphaN:  42\n",
      "testing alphaN:  43\n",
      "testing alphaN:  44\n",
      "testing alphaN:  45\n",
      "testing alphaN:  46\n",
      "testing alphaN:  47\n",
      "testing alphaN:  48\n",
      "testing alphaN:  49\n",
      "testing alphaN:  50\n",
      "testing alphaN:  51\n",
      "testing alphaN:  52\n",
      "testing alphaN:  53\n",
      "testing alphaN:  54\n",
      "testing alphaN:  55\n",
      "testing alphaN:  56\n",
      "testing alphaN:  57\n",
      "testing alphaN:  58\n",
      "testing alphaN:  59\n",
      "testing alphaN:  60\n",
      "testing alphaN:  61\n",
      "testing alphaN:  62\n",
      "testing alphaN:  63\n",
      "testing alphaN:  64\n",
      "testing alphaN:  65\n",
      "testing alphaN:  66\n",
      "testing alphaN:  67\n",
      "testing alphaN:  68\n",
      "testing alphaN:  69\n",
      "testing alphaN:  70\n",
      "testing alphaN:  71\n",
      "testing alphaN:  72\n",
      "testing alphaN:  73\n",
      "testing alphaN:  74\n",
      "testing alphaN:  75\n",
      "testing alphaN:  76\n",
      "testing alphaN:  77\n",
      "testing alphaN:  78\n",
      "testing alphaN:  79\n",
      "testing alphaN:  80\n",
      "testing alphaN:  81\n",
      "testing alphaN:  82\n",
      "testing alphaN:  83\n",
      "testing alphaN:  84\n",
      "testing alphaN:  85\n",
      "testing alphaN:  86\n",
      "testing alphaN:  87\n",
      "testing alphaN:  88\n",
      "testing alphaN:  89\n",
      "testing alphaN:  90\n",
      "testing alphaN:  91\n",
      "testing alphaN:  92\n",
      "testing alphaN:  93\n",
      "testing alphaN:  94\n",
      "testing alphaN:  95\n",
      "testing alphaN:  96\n",
      "testing alphaN:  97\n",
      "testing alphaN:  98\n",
      "testing alphaN:  99\n",
      "testing alphaN:  100\n",
      "testing alphaN:  101\n",
      "testing alphaN:  102\n",
      "testing alphaN:  103\n",
      "testing alphaN:  104\n",
      "testing alphaN:  105\n",
      "testing alphaN:  106\n",
      "testing alphaN:  107\n",
      "testing alphaN:  108\n",
      "testing alphaN:  109\n",
      "testing alphaN:  110\n",
      "testing alphaN:  111\n",
      "testing alphaN:  112\n",
      "testing alphaN:  113\n",
      "testing alphaN:  114\n",
      "testing alphaN:  115\n",
      "testing alphaN:  116\n",
      "testing alphaN:  117\n",
      "testing alphaN:  118\n",
      "testing alphaN:  119\n",
      "testing alphaN:  120\n",
      "testing alphaN:  121\n",
      "testing alphaN:  122\n",
      "testing alphaN:  123\n",
      "testing alphaN:  124\n",
      "testing alphaN:  125\n",
      "testing alphaN:  126\n",
      "testing alphaN:  127\n",
      "testing alphaN:  128\n",
      "testing alphaN:  129\n",
      "testing alphaN:  130\n",
      "testing alphaN:  131\n",
      "testing alphaN:  132\n",
      "testing alphaN:  133\n",
      "testing alphaN:  134\n",
      "testing alphaN:  135\n",
      "testing alphaN:  136\n",
      "testing alphaN:  137\n",
      "testing alphaN:  138\n",
      "testing alphaN:  139\n",
      "testing alphaN:  140\n",
      "testing alphaN:  141\n",
      "testing alphaN:  142\n",
      "testing alphaN:  143\n",
      "testing alphaN:  144\n",
      "testing alphaN:  145\n",
      "testing alphaN:  146\n",
      "testing alphaN:  147\n",
      "testing alphaN:  148\n",
      "testing alphaN:  149\n",
      "testing alphaN:  150\n",
      "testing alphaN:  151\n",
      "testing alphaN:  152\n",
      "testing alphaN:  153\n",
      "testing alphaN:  154\n",
      "testing alphaN:  155\n",
      "testing alphaN:  156\n",
      "testing alphaN:  157\n",
      "testing alphaN:  158\n",
      "testing alphaN:  159\n",
      "testing alphaN:  160\n",
      "testing alphaN:  161\n",
      "testing alphaN:  162\n",
      "testing alphaN:  163\n",
      "testing alphaN:  164\n",
      "testing alphaN:  165\n",
      "testing alphaN:  166\n",
      "testing alphaN:  167\n",
      "testing alphaN:  168\n",
      "testing alphaN:  169\n",
      "testing alphaN:  170\n",
      "testing alphaN:  171\n",
      "testing alphaN:  172\n",
      "testing alphaN:  173\n",
      "testing alphaN:  174\n",
      "testing alphaN:  175\n",
      "testing alphaN:  176\n",
      "testing alphaN:  177\n",
      "testing alphaN:  178\n",
      "testing alphaN:  179\n",
      "testing alphaN:  180\n",
      "testing alphaN:  181\n",
      "testing alphaN:  182\n",
      "testing alphaN:  183\n",
      "testing alphaN:  184\n",
      "testing alphaN:  185\n",
      "testing alphaN:  186\n",
      "testing alphaN:  187\n",
      "testing alphaN:  188\n",
      "testing alphaN:  189\n",
      "testing alphaN:  190\n",
      "testing alphaN:  191\n",
      "testing alphaN:  192\n",
      "testing alphaN:  193\n",
      "testing alphaN:  194\n",
      "testing alphaN:  195\n",
      "testing alphaN:  196\n",
      "testing alphaN:  197\n",
      "testing alphaN:  198\n",
      "testing alphaN:  199\n",
      "testing alphaN:  200\n",
      "testing alphaN:  201\n",
      "testing alphaN:  202\n",
      "testing alphaN:  203\n",
      "testing alphaN:  204\n",
      "testing alphaN:  205\n",
      "testing alphaN:  206\n",
      "testing alphaN:  207\n",
      "testing alphaN:  208\n",
      "testing alphaN:  209\n",
      "testing alphaN:  210\n",
      "testing alphaN:  211\n",
      "testing alphaN:  212\n",
      "testing alphaN:  213\n",
      "testing alphaN:  214\n",
      "testing alphaN:  215\n",
      "testing alphaN:  216\n",
      "testing alphaN:  217\n",
      "testing alphaN:  218\n",
      "testing alphaN:  219\n",
      "testing alphaN:  220\n",
      "testing alphaN:  221\n",
      "testing alphaN:  222\n",
      "testing alphaN:  223\n",
      "testing alphaN:  224\n",
      "testing alphaN:  225\n",
      "testing alphaN:  226\n",
      "testing alphaN:  227\n",
      "testing alphaN:  228\n"
     ]
    }
   ],
   "source": [
    "# compare the two GPT-preview models.\n",
    "model_1 = 16\n",
    "model_2 = None\n",
    "alphaN = 1\n",
    "sign_change_refit = False\n",
    "while sign_change_refit == False: # increment alphaN until we find a sign change.\n",
    "        print(\"testing alphaN: \", alphaN)\n",
    "        sign_change_amip, sign_change_refit, original_beta_diff, new_beta_diff_amip, new_beta_diff_refit, indices = LogisticAMIP.AMIP_sign_change(gpt_AMIP, alphaN, model_1, model_2, \n",
    "                         method = \"1sN\", refit = True)\n",
    "        alphaN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it takes  229  iterations w/out the specified models to find a sign change.\n"
     ]
    }
   ],
   "source": [
    "# it takes \n",
    "sign_change_amip, sign_change_refit, original_beta_diff, new_beta_diff_amip, new_beta_diff_refit, indices\n",
    "print(\"it takes \", alphaN, \" iterations w/out the specified models to find a sign change.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuel check (for each k) on the MIS! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatBotArenaDataDropped = results_nonrobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tuple = chatBotArenaDataDropped[(1, 3)] # = 0 # change none to -1 (gpt-4-1106-preview).\n",
    "new_tuple = tuple(-1 if i == 1 and val is None else val for i, val in enumerate(old_tuple))\n",
    "chatBotArenaDataDropped[(1, 3)] = new_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 3): (21,\n",
       "  -1,\n",
       "  -0.006288794711674339,\n",
       "  0.0031921260689085195,\n",
       "  array([46259,  3527,  6212])),\n",
       " (3, 25): (6,\n",
       "  41,\n",
       "  0.12679781444443133,\n",
       "  -0.0030410188523184445,\n",
       "  array([35121, 52352, 55829, 42442, 40406,  3483, 20172, 25481, 17355,\n",
       "         13244, 22020,  6887, 22343, 39307, 17575,  5270, 53348, 21912,\n",
       "         52752, 49539, 10429, 39612, 47469,   661, 37846])),\n",
       " (5, 17): (41,\n",
       "  47,\n",
       "  0.07868100815171142,\n",
       "  -0.004423403115031421,\n",
       "  array([49509, 49513, 54538, 56334, 29584, 14102, 50133, 55511, 13835,\n",
       "         20425, 27552, 38755, 51339, 27090, 12812, 31461, 27279])),\n",
       " (10, 1): (5,\n",
       "  4,\n",
       "  -0.0011897670601963561,\n",
       "  0.0008384212669726443,\n",
       "  array([34831])),\n",
       " (20, 1): (29,\n",
       "  48,\n",
       "  -0.008398628526396834,\n",
       "  0.0006804081985379851,\n",
       "  array([38092]))}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatBotArenaDataDropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-aN</th>\n",
       "      <th>playerA</th>\n",
       "      <th>playerB</th>\n",
       "      <th>original_beta_diff</th>\n",
       "      <th>new_beta_diff_refit</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>[46259, 3527, 6212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 25)</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0.126798</td>\n",
       "      <td>-0.003041</td>\n",
       "      <td>[35121, 52352, 55829, 42442, 40406, 3483, 2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 17)</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>0.078681</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>[49509, 49513, 54538, 56334, 29584, 14102, 501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>[34831]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 1)</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.008399</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>[38092]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k-aN  playerA  playerB  original_beta_diff  new_beta_diff_refit  \\\n",
       "0   (1, 3)       22        0           -0.006289             0.003192   \n",
       "1  (3, 25)        7       42            0.126798            -0.003041   \n",
       "2  (5, 17)       42       48            0.078681            -0.004423   \n",
       "3  (10, 1)        6        5           -0.001190             0.000838   \n",
       "4  (20, 1)       30       49           -0.008399             0.000680   \n",
       "\n",
       "                                             indices  \n",
       "0                                [46259, 3527, 6212]  \n",
       "1  [35121, 52352, 55829, 42442, 40406, 3483, 2017...  \n",
       "2  [49509, 49513, 54538, 56334, 29584, 14102, 501...  \n",
       "3                                            [34831]  \n",
       "4                                            [38092]  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for (k, aN), (playerA, playerB, original_beta_diff, new_beta_diff_refit, indices) in chatBotArenaDataDropped.items():\n",
    "    rows.append({\n",
    "        \"k-aN\": (k, aN),\n",
    "        \"playerA\": playerA + 1, # to account for the reference index.\n",
    "        \"playerB\": playerB + 1,\n",
    "        \"original_beta_diff\": original_beta_diff,\n",
    "        \"new_beta_diff_refit\": new_beta_diff_refit,\n",
    "        \"indices\": indices\n",
    "    })\n",
    "cba_results = pd.DataFrame(rows)\n",
    "cba_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_inds = cba_results['indices'][4]\n",
    "X_new = np.delete(X, mis_inds, axis=0)\n",
    "y_new = np.delete(y, mis_inds, axis=0)\n",
    "\n",
    "res_full = run_logistic_regression(X,\n",
    "                                    y,\n",
    "                                    fit_intercept=False, \n",
    "                                    penalty=None\n",
    "                                    )\n",
    "res_dropped = run_logistic_regression(X_new,\n",
    "                                y_new,\n",
    "                                fit_intercept=False, \n",
    "                                penalty=None\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.008398628526396834, 0.0006804081988217581)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player1 = cba_results['playerA'][4] - 1\n",
    "player2 = cba_results['playerB'][4] - 1\n",
    "beta_diff = res_full.coef_[0][player1] - res_full.coef_[0][player2]\n",
    "beta_diff_refit = res_dropped.coef_[0][player1] - res_dropped.coef_[0][player2]\n",
    "# res_full.coef_[0][player1], res_dropped.coef_[0][player1] # for the \"None\" version\n",
    "beta_diff, beta_diff_refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46259,  3527,  6212])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cba_results['indices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the mapping.\n",
    "id_to_player = {v: k for k, v in player_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the results.\n",
    "cba_results.head()\n",
    "cba_results['playerA_Name'] = cba_results['playerA'].map(id_to_player)\n",
    "cba_results['playerB_Name'] = cba_results['playerB'].map(id_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
