{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from package.RankAMIP.logistic import run_logistic_regression\n",
    "from package.RankAMIP.data_script import make_BT_design_matrix\n",
    "from package.RankAMIP.logistic import LogisticAMIP\n",
    "from package.RankAMIP.logistic import find_closest_matchups\n",
    "from package.RankAMIP.logistic import isRankingRobust\n",
    "from package.RankAMIP.data_script import break_ties_randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is LLM-as-a-Judge Chatbot Arena Data-Dropping Robust?\n",
    "\n",
    "The potsawee/chatbot-arena-llm-judges dataset is a collection of evaluations where large language models (LLMs) act as judges, assessing the quality of responses generated by other LLMs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets from https://huggingface.co/datasets/potsawee/chatbot-arena-llm-judges\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"potsawee/chatbot-arena-llm-judges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'question', 'answer_a', 'answer_b'],\n",
      "        num_rows: 49938\n",
      "    })\n",
      "})\n",
      "{'id': 65089, 'model_a': 'gpt-3.5-turbo-0613', 'model_b': 'mistral-medium', 'winner_model_a': 0, 'winner_model_b': 0, 'winner_tie': 1, 'question': 'explain function calling. how would you call a function?', 'answer_a': 'Function calling is the process of invoking or executing a function in a programming language. To call a function, you need to use the function\\'s name followed by parentheses \"()\". Within the parentheses, you can pass arguments if the function requires any.\\n\\nHere is an example of how to call a function in Python:\\n\\n```python\\n# Define a function\\ndef greet(name):\\n    print(\"Hello, \" + name + \"!\")\\n\\n# Call the function\\ngreet(\"John\")\\n```\\n\\nIn this example, the function \"greet\" is defined with a single parameter \"name\" which is used to print a greeting message. To call the function and pass an argument, we write \"greet(\"John\")\". This will execute the function and print \"Hello, John!\".\\n\\nIt is important to note that the function should be defined before calling it in most programming languages, as the interpreter needs to know about the function\\'s existence before it can be called.', 'answer_b': 'Function calling is the process of invoking a function in a program. A function is a block of code that performs a specific task and can be reused multiple times in a program. Functions help to organize and modularize code, making it more readable and maintainable.\\n\\nTo call a function, you simply write the name of the function followed by parentheses () containing any arguments or parameters that the function requires. Here\\'s an example:\\n```\\nfunction greet(name) {\\n  console.log(\"Hello, \" + name);\\n}\\n\\n// Call the greet function and pass in the argument \"Alice\"\\ngreet(\"Alice\");\\n```\\nIn the example above, the function `greet` takes one parameter, `name`, which is used inside the function to print a greeting message. To call the function, we write the name of the function (`greet`) followed by parentheses containing the argument `\"Alice\"`. When the function is called, the argument `\"Alice\"` is passed to the function, where it is assigned to the `name` parameter. The function then uses the `name` parameter to print the greeting message `\"Hello, Alice\"`.\\n\\nFunctions can also return values, which can be assigned to variables or used in expressions. For example:\\n```\\nfunction addNumbers(a, b) {\\n  return a + b;\\n}\\n\\n// Call the addNumbers function and assign the result to the variable sum\\nvar sum = addNumbers(3, 5);\\nconsole.log(sum); // Output: 8\\n```\\nIn the example above, the function `addNumbers` takes two parameters, `a` and `b`, adds them together, and returns the result. To call the function, we write the name of the function (`addNumbers`) followed by parentheses containing the arguments `3` and `5`. The function calculates the sum of the two arguments (`3 + 5 = 8`) and returns the result (`8`). We then assign the result to the variable `sum` and print it to the console.'}\n"
     ]
    }
   ],
   "source": [
    "# inspect the available splits\n",
    "print(ds)  \n",
    "# grab the ‘train’ split (or whatever splits ds has)\n",
    "train = ds[\"train\"]\n",
    "# look at the first example\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_a</th>\n",
       "      <th>answer_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292873</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Construct a rap battle, in the style of Epic R...</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "      <td>(Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313413</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Why water is not used in bath tub?</td>\n",
       "      <td>Water is actually used in a bath tub. A bath t...</td>\n",
       "      <td>Water is not used in a bath tub because it is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     model_a              model_b  winner_model_a  \\\n",
       "0   65089          gpt-3.5-turbo-0613       mistral-medium               0   \n",
       "1   96401            llama-2-13b-chat  mistral-7b-instruct               1   \n",
       "2  198779                   koala-13b   gpt-3.5-turbo-0314               0   \n",
       "3  292873                  vicuna-13b           gpt-4-0314               0   \n",
       "4  313413  mixtral-8x7b-instruct-v0.1           vicuna-13b               1   \n",
       "\n",
       "   winner_model_b  winner_tie  \\\n",
       "0               0           1   \n",
       "1               0           0   \n",
       "2               1           0   \n",
       "3               1           0   \n",
       "4               0           0   \n",
       "\n",
       "                                            question  \\\n",
       "0  explain function calling. how would you call a...   \n",
       "1  How can I create a test set for a very rare ca...   \n",
       "2  What is the best way to travel from Tel-Aviv t...   \n",
       "3  Construct a rap battle, in the style of Epic R...   \n",
       "4                 Why water is not used in bath tub?   \n",
       "\n",
       "                                            answer_a  \\\n",
       "0  Function calling is the process of invoking or...   \n",
       "1  Creating a test set for a very rare category c...   \n",
       "2  The best way to travel from Tel Aviv to Jerusa...   \n",
       "3  [Zeus]\\nYo, it's the king of the gods on the m...   \n",
       "4  Water is actually used in a bath tub. A bath t...   \n",
       "\n",
       "                                            answer_b  \n",
       "0  Function calling is the process of invoking a ...  \n",
       "1  When building a classifier for a very rare cat...  \n",
       "2  The best way to travel from Tel-Aviv to Jerusa...  \n",
       "3  (Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...  \n",
       "4  Water is not used in a bath tub because it is ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move 'gpt-4-1106-preview' to index 0 (so that it is the baseline model).\n",
    "mask = (df['model_a'] == 'gpt-4-1106-preview') | (df['model_b'] == 'gpt-4-1106-preview')\n",
    "df = pd.concat([df[mask], df[~mask]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique model names: 64\n"
     ]
    }
   ],
   "source": [
    "# the unique model names\n",
    "model_a_names = df['model_a'].unique()\n",
    "model_b_names = df['model_b'].unique()\n",
    "model_names = np.unique(np.concatenate((model_a_names, model_b_names)))\n",
    "\n",
    "print(f\"Number of unique model names: {len(model_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ties: 15641\n",
      "Proportion of ties: 31.32%\n"
     ]
    }
   ],
   "source": [
    "ties = df[df['winner_tie'] == 1]\n",
    "print(f\"Number of ties: {len(ties)}\")\n",
    "# proportion of ties.\n",
    "print(f\"Proportion of ties: {len(ties) / len(df):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the rows that correspond to ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_a             model_b  winner_model_a\n",
       "0  gpt-4-1106-preview        wizardlm-70b               1\n",
       "3  gpt-4-1106-preview          claude-2.1               1\n",
       "4  gpt-4-1106-preview          gpt-4-0613               0\n",
       "6  gpt-3.5-turbo-0613  gpt-4-1106-preview               0\n",
       "7              palm-2  gpt-4-1106-preview               0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows in df with df['winner_tie'] == 1\n",
    "df_ties_dropped = df[df['winner_tie'] == 0]\n",
    "df_ties_dropped.shape\n",
    "rawBT_noTies = df_ties_dropped[['model_a', 'model_b', 'winner_model_a']]\n",
    "rawBT_noTies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34297, 63), (34297,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create BT design matrix.\n",
    "X, y, player_to_id = make_BT_design_matrix(rawBT_noTies)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Top-k Robustness Check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [1, 3, 5, 10, 20]\n",
    "\n",
    "results = {}\n",
    "for k in ks:\n",
    "    alphaN = 1\n",
    "    chatbotA = -1\n",
    "    while chatbotA == -1:\n",
    "        chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices = isRankingRobust(k, alphaN, X, y)\n",
    "        results[(k, alphaN)] = (chatbotA, chatbotB, chatbotOriginalBetaDiff, chatNewBetaDiff, chatIndices)\n",
    "        alphaN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 4): (24,\n",
       "  None,\n",
       "  0.013837807361522918,\n",
       "  -0.004433233431111085,\n",
       "  array([1977, 1796,  823, 1069])),\n",
       " (3, 15): (21,\n",
       "  42,\n",
       "  0.16061075763847033,\n",
       "  -0.0005652617887471623,\n",
       "  array([22886, 26632, 33446, 31675, 13794,  7375, 32166, 25601, 13680,\n",
       "         11507, 15159, 16105, 16276, 31866, 24294])),\n",
       " (5, 10): (42,\n",
       "  7,\n",
       "  0.0920873022068236,\n",
       "  -0.006170522526522726,\n",
       "  array([2193, 1084, 1636, 4485, 3098, 1113, 4005, 4004, 2361, 4057])),\n",
       " (10, 2): (2,\n",
       "  8,\n",
       "  0.006779695894059357,\n",
       "  -0.00013762951326445894,\n",
       "  array([ 149, 4412])),\n",
       " (20, 2): (3,\n",
       "  25,\n",
       "  0.005544624303261525,\n",
       "  -0.0019872249816650367,\n",
       "  array([7858, 8478]))}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the (k, alpha N) pairs that are non-robust.\n",
    "results_nonrobust = {k: v for k, v in results.items() if v[0] != -1}\n",
    "results_nonrobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.RankAMIP.plot_util import *\n",
    "rankings = return_rankings_list(X, y, results, 1, 4, player_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rankings for the full arena.\n",
    "filename_to_save = 'fig/top20_LLMAren.png'\n",
    "plot_title = 'Model Rankings in LLM Arena'\n",
    "plot_bt_scores(X, y, rankings, alphaN, 20, plot_title, filename_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary statistics on the pair that changed 1st, 2nd place rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in results.\n",
    "import pickle\n",
    "\n",
    "with open(\"results/LLMArenaNonrobust.pkl\", \"rb\") as f:\n",
    "    LLMArenaDataDropped = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34297, 9)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 evals were dropped to change models 24 and None (aka, 0).\n",
    "# player_to_id # (24 + 1 (adding in the none index): 'gpt-4-0125-preview', 0: 'gpt-4-1106-preview')\n",
    "# load in chatBotArena_noTies.csv\n",
    "LLMArena_noTies = pd.read_csv(\"data/LLMArena_noTies.csv\")\n",
    "LLMArena_noTies.head()\n",
    "LLMArena_noTies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games between GPT-4-1106 and GPT-4-0125:  58\n"
     ]
    }
   ],
   "source": [
    "## Count number of games between the two models that changed rankings.\n",
    "is_gpt41106_gpt40125 = (\n",
    "    (LLMArena_noTies['model_a'].str.contains('gpt-4-0125-preview') & LLMArena_noTies['model_b'].str.contains('gpt-4-1106-preview')) |\n",
    "    (LLMArena_noTies['model_a'].str.contains('gpt-4-1106-preview') & LLMArena_noTies['model_b'].str.contains('gpt-4-0125-preview'))\n",
    ")\n",
    "\n",
    "num_gpt41106_gpt40125 = LLMArena_noTies[is_gpt41106_gpt40125].shape[0]\n",
    "print(\"Number of games between GPT-4-1106 and GPT-4-0125: \", num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of games per model pair: 27.793354943273908\n"
     ]
    }
   ],
   "source": [
    "# model pairs (sorted to group symmetric pairs)\n",
    "LLMArena_noTies['model_pair'] = LLMArena_noTies.apply(lambda row: tuple(sorted([row['model_a'], row['model_b']])), axis=1)\n",
    "\n",
    "# Count number of games per model pair\n",
    "pair_counts = LLMArena_noTies['model_pair'].value_counts()\n",
    "\n",
    "# Compute average\n",
    "average_games_per_pair = pair_counts.mean()\n",
    "print(\"Average number of games per model pair:\", average_games_per_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of games that GPT-4-0125 won:  0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "# Find the win margin between 'gpt-4-0125-preview' and 'gpt-4-1106-preview'\n",
    "# that is, find all games that are between the two models.\n",
    "dfFlippedRanking = LLMArena_noTies[is_gpt41106_gpt40125]\n",
    "# find the win margin\n",
    "## Count number of games between that 'gpt-4-0125-preview' won.\n",
    "gpt40125_wins = (\n",
    "    (dfFlippedRanking['model_a'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_a'] == 1) |\n",
    "    (dfFlippedRanking['model_b'].str.contains('gpt-4-0125-preview') & dfFlippedRanking['winner_model_b'] == 1)\n",
    ")\n",
    "num_gpt40125_wins = dfFlippedRanking[gpt40125_wins].shape[0]\n",
    "print(\"Proportion of games that GPT-4-0125 won: \", num_gpt40125_wins / num_gpt41106_gpt40125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player involvement in dropped matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tuple = LLMArenaDataDropped[(1,4)] # = 0 # change none to a -1 (gpt-4-1106-preview).\n",
    "new_tuple = tuple(-1 if i == 1 and val is None else val for i, val in enumerate(old_tuple))\n",
    "results_nonrobust[(1, 4)] = new_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 4): (24,\n",
       "  -1,\n",
       "  0.013837807361522918,\n",
       "  -0.004433233431111085,\n",
       "  array([1977, 1796,  823, 1069])),\n",
       " (3, 15): (21,\n",
       "  42,\n",
       "  0.16061075763847033,\n",
       "  -0.0005652617887471623,\n",
       "  array([22886, 26632, 33446, 31675, 13794,  7375, 32166, 25601, 13680,\n",
       "         11507, 15159, 16105, 16276, 31866, 24294])),\n",
       " (5, 10): (42,\n",
       "  7,\n",
       "  0.0920873022068236,\n",
       "  -0.006170522526522726,\n",
       "  array([2193, 1084, 1636, 4485, 3098, 1113, 4005, 4004, 2361, 4057])),\n",
       " (10, 2): (2,\n",
       "  8,\n",
       "  0.006779695894059357,\n",
       "  -0.00013762951326445894,\n",
       "  array([ 149, 4412])),\n",
       " (20, 2): (3,\n",
       "  25,\n",
       "  0.005544624303261525,\n",
       "  -0.0019872249816650367,\n",
       "  array([7858, 8478]))}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nonrobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-aN</th>\n",
       "      <th>playerA</th>\n",
       "      <th>playerB</th>\n",
       "      <th>original_beta_diff</th>\n",
       "      <th>new_beta_diff_refit</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>[1977, 1796, 823, 1069]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 15)</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>0.160611</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>[22886, 26632, 33446, 31675, 13794, 7375, 3216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>0.092087</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>[2193, 1084, 1636, 4485, 3098, 1113, 4005, 400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>[149, 4412]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 2)</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>[7858, 8478]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k-aN  playerA  playerB  original_beta_diff  new_beta_diff_refit  \\\n",
       "0   (1, 4)       25        0            0.013838            -0.004433   \n",
       "1  (3, 15)       22       43            0.160611            -0.000565   \n",
       "2  (5, 10)       43        8            0.092087            -0.006171   \n",
       "3  (10, 2)        3        9            0.006780            -0.000138   \n",
       "4  (20, 2)        4       26            0.005545            -0.001987   \n",
       "\n",
       "                                             indices  \n",
       "0                            [1977, 1796, 823, 1069]  \n",
       "1  [22886, 26632, 33446, 31675, 13794, 7375, 3216...  \n",
       "2  [2193, 1084, 1636, 4485, 3098, 1113, 4005, 400...  \n",
       "3                                        [149, 4412]  \n",
       "4                                       [7858, 8478]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the DataFrame\n",
    "rows = []\n",
    "for (k, aN), (playerA, playerB, original_beta_diff, new_beta_diff_refit, indices) in results_nonrobust.items():\n",
    "    rows.append({\n",
    "        \"k-aN\": (k, aN),\n",
    "        \"playerA\": playerA + 1, # to account for the None index.\n",
    "        \"playerB\": playerB + 1,\n",
    "        \"original_beta_diff\": original_beta_diff,\n",
    "        \"new_beta_diff_refit\": new_beta_diff_refit,\n",
    "        \"indices\": indices\n",
    "    })\n",
    "llm_arena_results = pd.DataFrame(rows)\n",
    "llm_arena_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the mapping.\n",
    "id_to_player = {v: k for k, v in player_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    gpt-4-0125-preview\n",
       "1            gpt-4-0314\n",
       "2      qwen1.5-72b-chat\n",
       "3            gemini-pro\n",
       "4      claude-instant-1\n",
       "Name: playerA, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_arena_results['playerA'].map(id_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            gpt-4-1106-preview\n",
       "1              qwen1.5-72b-chat\n",
       "2                mistral-medium\n",
       "3    mixtral-8x7b-instruct-v0.1\n",
       "4               pplx-70b-online\n",
       "Name: playerB, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_arena_results['playerB'].map(id_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the results.\n",
    "llm_arena_results = pd.read_csv(\"results/LLMArenaNonrobust.csv\")\n",
    "llm_arena_results.head()\n",
    "llm_arena_results['playerA_Name'] = llm_arena_results['playerA'].map(id_to_player)\n",
    "llm_arena_results['playerB_Name'] = llm_arena_results['playerB'].map(id_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_a</th>\n",
       "      <th>answer_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>460124099</td>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider any natural number. if the number is ...</td>\n",
       "      <td>Yes, this process will end in a loop for some ...</td>\n",
       "      <td>Consider a natural number. If the number is ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>549514947</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Come up with a conspiracy theory about what is...</td>\n",
       "      <td>A conspiracy theory about \"Q*\" in the context ...</td>\n",
       "      <td>Sure, here's a conspiracy theory about \"Q*\" in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          model_a          model_b  winner_model_a  \\\n",
       "7858  460124099      chatglm3-6b  pplx-70b-online               1   \n",
       "8478  549514947  pplx-70b-online      chatglm3-6b               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \\\n",
       "7858               0           0   \n",
       "8478               1           0   \n",
       "\n",
       "                                               question  \\\n",
       "7858  consider any natural number. if the number is ...   \n",
       "8478  Come up with a conspiracy theory about what is...   \n",
       "\n",
       "                                               answer_a  \\\n",
       "7858  Yes, this process will end in a loop for some ...   \n",
       "8478  A conspiracy theory about \"Q*\" in the context ...   \n",
       "\n",
       "                                               answer_b  \n",
       "7858  Consider a natural number. If the number is ev...  \n",
       "8478  Sure, here's a conspiracy theory about \"Q*\" in...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each index, find the in\n",
    "indices = [7858, 8478]\n",
    "LLMArena_noTies.iloc[indices]\n",
    "# find the proportion of games where neither "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[149, 4412]: this is a case where the points that were dropped are instances where *one* of the models (gemini-pro) beat a super strong model (gpt-4-1106-preview) twice.\n",
    "\n",
    "[7858, 8478]: this is a case where one of the models (pplx-70b-online) lost twice to a super low-ranked model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-aN</th>\n",
       "      <th>playerA</th>\n",
       "      <th>playerB</th>\n",
       "      <th>original_beta_diff</th>\n",
       "      <th>new_beta_diff_refit</th>\n",
       "      <th>indices</th>\n",
       "      <th>playerA_Name</th>\n",
       "      <th>playerB_Name</th>\n",
       "      <th>prop_both</th>\n",
       "      <th>prop_one</th>\n",
       "      <th>prop_neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>[1977 1796  823 1069]</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 15)</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>0.160611</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>[22886 26632 33446 31675 13794  7375 32166 256...</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>0.092087</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>[2193 1084 1636 4485 3098 1113 4005 4004 2361 ...</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>[ 149 4412]</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 2)</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>[7858 8478]</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k-aN  playerA  playerB  original_beta_diff  new_beta_diff_refit  \\\n",
       "0   (1, 4)       25        0            0.013838            -0.004433   \n",
       "1  (3, 15)       22       43            0.160611            -0.000565   \n",
       "2  (5, 10)       43        8            0.092087            -0.006171   \n",
       "3  (10, 2)        3        9            0.006780            -0.000138   \n",
       "4  (20, 2)        4       26            0.005545            -0.001987   \n",
       "\n",
       "                                             indices        playerA_Name  \\\n",
       "0                              [1977 1796  823 1069]  gpt-4-0125-preview   \n",
       "1  [22886 26632 33446 31675 13794  7375 32166 256...          gpt-4-0314   \n",
       "2  [2193 1084 1636 4485 3098 1113 4005 4004 2361 ...    qwen1.5-72b-chat   \n",
       "3                                        [ 149 4412]          gemini-pro   \n",
       "4                                        [7858 8478]    claude-instant-1   \n",
       "\n",
       "                 playerB_Name  prop_both  prop_one  prop_neither  \n",
       "0          gpt-4-1106-preview        1.0       0.0           0.0  \n",
       "1            qwen1.5-72b-chat        0.0       1.0           0.0  \n",
       "2              mistral-medium        0.0       1.0           0.0  \n",
       "3  mixtral-8x7b-instruct-v0.1        0.0       1.0           0.0  \n",
       "4             pplx-70b-online        0.0       1.0           0.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_arena_results_with_props = add_match_proportions(llm_arena_results, LLMArena_noTies)\n",
    "llm_arena_results_with_props.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
